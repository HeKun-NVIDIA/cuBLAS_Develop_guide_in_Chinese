# cuBLAS开发指南中文版

## 2.使用cuBLASAPI

本节介绍如何使用 cuBLAS 库 API。

### 2.1.1. Error status

所有 cuBLAS 库函数调用都返回错误状态 [cublasStatus_t](https://docs.nvidia.com/cuda/cublas/index.html#cublasstatus_t)。

### 2.1.2. cuBLAS context


应用程序必须通过调用 `cublasCreate()` 函数来初始化 cuBLAS 库上下文的句柄。然后，将句柄显式传递给每个后续的库函数调用。一旦应用程序完成使用该库，它必须调用函数` cublasDestroy() `以释放与 cuBLAS 库上下文关联的资源。

这种方法允许用户在使用多个主机线程和多个 GPU 时显式控制库设置。例如，应用程序可以使用 `cudaSetDevice()` 将不同的设备与不同的主机线程相关联，并且在每个主机线程中，它可以初始化 cuBLAS 库上下文的唯一句柄，它将使用与该主机线程关联的特定设备。然后，使用不同句柄进行的 cuBLAS 库函数调用将自动将计算分派到不同的设备。

假定与特定 cuBLAS 上下文关联的设备在相应的 `cublasCreate() `和 `cublasDestroy()` 调用之间保持不变。为了让 cuBLAS 库在同一主机线程中使用不同的设备，应用程序必须通过调用 `cudaSetDevice()` 设置要使用的新设备，然后通过调用创建另一个与新设备关联的 cuBLAS 上下文`cublasCreate()`。

cuBLAS 库上下文与 `cublasCreate()` 调用时当前的 CUDA 上下文紧密耦合。使用多个 CUDA 上下文的应用程序需要为每个 CUDA 上下文创建一个 cuBLAS 上下文，并确保前者永远不会超过后者。

### 2.1.3. Thread Safety

该库是线程安全的，即使使用相同的句柄，也可以从多个主机线程调用其函数。 当多个线程共享同一个句柄时，当句柄配置发生更改时需要格外小心，因为该更改可能会影响所有线程中的后续 cuBLAS 调用。 对于手柄的破坏更是如此。 所以不建议多个线程共享同一个 cuBLAS 句柄。

### 2.1.4. Results reproducibility

根据设计，给定工具包版本的所有 cuBLAS API 例程在具有相同架构和相同数量 SM 的 GPU 上执行时，每次运行都会生成相同的按位结果。但是，不能保证跨工具包版本的逐位再现性，因为实现可能会因某些实现更改而有所不同。

此保证仅在单个 CUDA 流处于活动状态时有效。如果多个并发流处于活动状态，则库可以通过选择不同的内部实现来优化总体性能。

**注意**：多流执行的不确定行为是由于库优化为并行流中运行的例程选择内部工作区。为了避免这种影响，用户可以：

* 使用 `cublasSetWorkspace()` 函数为每个使用的流提供单独的工作区，或
* 每个流有一个 cuBLAS 句柄，或
* 使用 cublasLtMatmul() 代替 `*gemm*()` 系列函数并提供用户拥有的工作空间，或
* 将调试环境变量 CUBLAS_WORKSPACE_CONFIG 设置为“:16:8”（可能会限制整体性能）或“:4096:8”（将 GPU 内存中的库占用量增加大约 24MiB）。


即使多个并发流共享一个 cuBLAS 句柄，这些设置中的任何一个都将允许确定性行为。
预计此行为将在未来版本中更改。

对于一些例程，例如 `cublas<t>symv` 和 `cublas<t>hemv`，可以使用例程 `cublasSetAtomicsMode()` 选择一个替代的明显更快的例程。在这种情况下，不能保证结果是按位可重现的，因为原子用于计算。

### 2.1.5. A.5. Scalar Parameters
有两类使用标量参数的函数：

* 通过引用主机或设备上的 alpha 或 beta 参数作为缩放因子的函数，例如 gemm。
* 在主机或设备上返回标量结果的函数，例如 amax()、amin、asum()、rotg()、rotmg()、dot() 和 nrm2()。

对于第一类函数，当指针模式设置为 `CUBLAS_POINTER_MODE_HOST` 时，标量参数 alpha 或 beta 可以在堆栈上或在堆上分配，不应放在托管内存中。下面，与这些功能相关的 CUDA 内核将以 alpha 或 beta 的值启动。因此，如果它们是在堆上分配的，即使内核启动是异步的，它们也可以在调用返回后立即释放。当指针模式设置为 `CUBLAS_POINTER_MODE_DEVICE` 时，alpha 或 beta 必须可以在设备上访问，并且在内核完成之前不应修改它们的值。请注意，由于 `cudaFree()` 执行隐式 `cudaDeviceSynchronize()`，因此 `cudaFree()` 仍然可以在调用后立即在 alpha 或 beta 上调用，但在这种情况下它会破坏使用此指针模式的目的。

对于第二类函数，当指针模式设置为 `CUBLAS_POINTER_MODE_HOST` 时，这些函数会阻塞 CPU，直到 GPU 完成计算并将结果复制回 Host。当指针模式设置为 `CUBLAS_POINTER_MODE_DEVICE` 时，这些函数会立即返回。在这种情况下，与矩阵和向量结果类似，标量结果仅在 GPU 上的例程执行完成时才准备就绪。这需要适当的同步才能从主机读取结果。

在任何一种情况下，指针模式 `CUBLAS_POINTER_MODE_DEVICE` 允许库函数与主机完全异步执行，即使 alpha 或 beta 是由先前的内核生成的。例如，当使用 cuBLAS 库实现求解线性系统和特征值问题的迭代方法时，可能会出现这种情况。

### 2.1.6 流并行

如果应用程序使用由多个独立任务计算的结果，则可以使用 CUDA™ 流来重叠在这些任务中执行的计算。

应用程序可以在概念上将每个流与每个任务相关联。为了实现任务之间的计算重叠，用户应该使用函数 `cudaStreamCreate()` 创建 CUDA™ 流，并在调用实际 cuBLAS 例程之前通过调用 `cublasSetStream()` 设置每个单独的 cuBLAS 库例程使用的流.请注意，`cublasSetStream()` 将用户提供的工作空间重置为默认工作空间池；请参见 [cublasSetWorkspace()](https://docs.nvidia.com/cuda/cublas/index.html#cublassetworkspace)。然后，在单独的流中执行的计算将尽可能在 GPU 上自动重叠。当单个任务执行的计算量相对较小且不足以使 GPU 充满工作时，这种方法特别有用。

我们建议使用带有标量参数的新 cuBLAS API，并在设备内存中通过引用传递结果，以在使用流时实现计算的最大重叠。

下一节将描述流的特定应用，即多个小内核的批处理。



### 2.1.7 批处理内核
在本节中，我们将解释如何使用流来批处理小内核的执行。例如，假设我们有一个应用程序，我们需要用密集矩阵进行许多小的独立矩阵乘法。

很明显，即使有数百万个小的独立矩阵，我们也无法达到与一个大矩阵相同的 GFLOPS 速率。例如，单个$n*n$大型矩阵-矩阵乘法针对$n^2$输入大小执行$n^3$运算，而 1024 个$\frac{n}{32} *\frac{n}{32}$小型矩阵-矩阵乘法针对相同输入大小执行$1024(\frac{n}{32})^3=\frac{n^3}{32}$运算。然而，同样清楚的是，与单个小矩阵相比，我们可以使用许多小的独立矩阵实现显着更好的性能。

GPU 的架构系列允许我们同时执行多个内核。因此，为了批量执行独立内核，我们可以在单独的流中运行它们中的每一个。特别是，在上面的示例中，我们可以使用函数 `cudaStreamCreate()` 创建 1024 个 CUDA™ 流，然后在每个对 `cublas<t>gemm()` 的调用前加上对 `cublasSetStream() `的调用，并为每个矩阵使用不同的流 -矩阵乘法（注意 `cublasSetStream()` 将用户提供的工作空间重置为默认工作空间池，请参阅 `cublasSetWorkspace()`）。这将确保尽可能同时执行不同的计算。尽管用户可以创建许多流，但实际上不可能同时执行超过 32 个并发内核。

### 2.1.8 缓存配置
在某些设备上，L1 缓存和共享内存使用相同的硬件资源。 可以直接使用 CUDA Runtime 函数 `cudaDeviceSetCacheConfig` 设置缓存配置。 也可以使用例程 `cudaFuncSetCacheConfig` 专门为某些功能设置缓存配置。 有关缓存配置设置的详细信息，请参阅 CUDA 运行时 API 文档。

因为从一种配置切换到另一种配置会影响内核并发性，所以 cuBLAS 库不设置任何缓存配置首选项，而是依赖于当前设置。 然而，一些 cuBLAS 例程，尤其是 Level-3 例程，严重依赖共享内存。 因此，缓存首选项设置可能会对它们的性能产生不利影响。

2.1.9 静态库支持
从 6.5 版开始，cuBLAS 库也在 Linux 和 Mac OS 上以静态形式作为 `libcublas_static.a` 提供。 静态 cuBLAS 库和所有其他静态数学库依赖于一个名为 `libculibos.a `的通用线程抽象层库。

例如，在 Linux 上，要使用 cuBLAS 编译一个小型应用程序，针对动态库，可以使用以下命令：

```bash
nvcc myCublasApp.c  -lcublas  -o myCublasApp
```

而要针对静态 cuBLAS 库进行编译，必须使用以下命令：
```bash
nvcc myCublasApp.c  -lcublas_static   -lculibos -o myCublasApp
```

也可以使用本机 Host C++ 编译器。 根据主机操作系统，链接行可能需要一些额外的库，如 pthread 或 dl。 建议在 Linux 上使用以下命令：

```bash
g++ myCublasApp.c  -lcublas_static   -lculibos -lcudart_static -lpthread -ldl -I <cuda-toolkit-path>/include -L <cuda-toolkit-path>/lib64 -o myCublasApp
```

**请注意**，在后一种情况下，不需要库 cuda。 如果需要，CUDA 运行时将尝试显式打开 cuda 库。 在没有安装 CUDA 驱动程序的系统的情况下，这允许应用程序优雅地管理此问题，并可能在仅 CPU 路径可用时运行。

从 11.2 版开始，使用类型化函数而不是扩展函数 (cublas**Ex()) 有助于在链接到静态 cuBLAS 库时减少二进制文件大小。



### 2.1.10 GEMM 算法数值行为
一些 GEMM 算法沿维度 K 拆分计算以增加 GPU 占用率，特别是当维度 K 与维度 M 和 N 相比较大时。当 cuBLAS 启发式或用户明确选择此类算法时，结果每个拆分确定性地求和到结果矩阵中以获得最终结果。

对于例程 `cublas<t>gemmEx` 和 `cublasGemmEx`，当计算类型大于输出类型时，拆分块的总和可能会导致一些中间溢出，从而产生最终的结果矩阵，其中包含一些溢出。如果所有点积在最终转换为输出类型之前已在计算类型中累积，则可能不会发生这些溢出。当 computeType 为 `CUDA_R_32F` 且 `Atype`、`Btype` 和 `Ctype` 在 `CUDA_R_16F` 中时，这种计算副作用很容易暴露。可以使用带有 [`cublasSetMathMode()`](https://docs.nvidia.com/cuda/cublas/index.html#cublassetmathmode) 的计算精度模式 `CUBLAS_MATH_DISALLOW_REDUCED_PRECISION_REDUCTION` 来控制此行为


2.1.11 Tensor Core使用
Tensor Core首次与 Volta GPU 一起引入（计算能力>=sm_70）并显着加速矩阵乘法。 从 cuBLAS 版本 11.0.0 开始，该库将尽可能自动使用 Tensor Core 功能，除非通过选择 cuBLAS 中的迂腐计算模式明确禁用它们（参见 `cublasSetMathMode()`, `cublasMath_t`）。

应该注意的是，该库将选择启用 Tensor Core 的实现，只要它确定它将提供最佳性能。

从 cuBLAS 版本 11.0.0 开始，使用Tensor Core不再对矩阵尺寸和内存对齐有任何限制。 但是，当矩阵维度和指针满足一定的内存对齐要求时，可以实现使用 Tensor Cores 时的最佳性能。 具体来说，必须满足以下所有条件才能充分利用 Tensor Cores 的性能：

* m % 8 == 0
* k % 8 == 0
* op_B == CUBLAS_OP_N || n%8 == 0
* intptr_t(A) % 16 == 0
* intptr_t(B) % 16 == 0
* intptr_t(C) % 16 == 0
* intptr_t(A+lda) % 16 == 0
* intptr_t(B+ldb) % 16 == 0
* intptr_t(C+ldc) % 16 == 0


### 2.1.12 CUDA 图支持
在大多数情况下，可以在 CUDA Graph 流捕获中捕获 cuBLAS 例程，而不受限制。

例外是将结果输出到主机缓冲区的例程（例如，配置指针模式 `CUBLAS_POINTER_MODE_HOST `时的 `cublas<t>dot`），因为它强制同步。

对于输入系数（如 alpha、beta），行为取决于指针模式设置：
* 在 `CUBLAS(LT)_POINTER_MODE_HOST` 的情况下，图中捕获了系数值。
* 在带有设备指针的指针模式的情况下 - 在图形执行时使用设备指针访问系数值。


**注意**：每次在新的 CUDA 图表中捕获 cuBLAS 例程时，cuBLAS 都会在设备上分配工作区内存。 仅当删除捕获期间使用的 cuBLAS 句柄时，才会释放此内存。 为避免这种情况，请使用 `cublasSetWorkspace()` 函数来提供用户拥有的工作区内存。

## 2.2 cuBLAS数据类型引用

### 2.2.1 cublasHandle_t
`cublasHandle_t` 类型是指向包含 cuBLAS 库上下文的不透明结构的指针类型。 cuBLAS 库上下文必须使用 `cublasCreate()` 初始化，并且返回的句柄必须传递给所有后续的库函数调用。 最后应该使用 `cublasDestroy()` 销毁上下文。


## 2.2.2 cublasStatus_t
该类型用于函数状态返回。 所有 cuBLAS 库函数都返回它们的状态，它可以有以下值。

<div class="tablenoborder">
                              <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="50%" id="d195e1030" rowspan="1" colspan="1">
                                          Value 
                                       </th>
                                       <th class="entry" valign="top" width="50%" id="d195e1033" rowspan="1" colspan="1">
                                          Meaning 
                                       </th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_SUCCESS</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">操作成功完成。</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_NOT_INITIALIZED</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">cuBLAS 库未初始化。 这通常是由于缺乏先验cublasCreate() 调用，由 cuBLAS 例程调用的 CUDA 运行时 API 中的错误，或硬件设置中的错误。

更正：在函数调用之前调用 cublasCreate() ； 并检查硬件、适当版本的驱动程序和 cuBLAS 库是否已正确安装。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_ALLOC_FAILED</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">cuBLAS 库中的资源分配失败。 这通常是由 cudaMalloc() 失败引起的。

更正：在函数调用之前，尽可能多地释放先前分配的内存。</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_INVALID_VALUE</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">向函数传递了不受支持的值或参数（例如，负向量大小）。

更正：确保传递的所有参数都具有有效值。</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_ARCH_MISMATCH</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">该功能需要设备架构中缺少的功能； 通常是由低于 5.0 的计算能力引起的。

更正：在具有适当计算能力的设备上编译和运行应用程序。</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_MAPPING_ERROR</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">访问 GPU 内存空间失败，这通常是由于绑定纹理失败造成的。

更正：在函数调用之前，取消绑定任何先前绑定的纹理。</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_EXECUTION_FAILED</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">GPU 程序无法执行。 这通常是由 GPU 上的内核启动失败引起的，这可能是由多种原因引起的。

更正：检查硬件、适当版本的驱动程序和 cuBLAS 库是否已正确安装。</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_INTERNAL_ERROR</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">内部 cuBLAS 操作失败。 此错误通常是由 cudaMemcpyAsync() 失败引起的。

更正：检查硬件、适当版本的驱动程序和 cuBLAS 库是否已正确安装。 此外，检查作为参数传递给例程的内存是否在例程完成之前没有被释放。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_NOT_SUPPORTED</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">不支持请求的功能</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e1030" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_LICENSE_ERROR</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e1033" rowspan="1" colspan="1">
                                          <p class="p">请求的功能需要一些许可证，并且在尝试检查当前许可时检测到错误。 如果许可证不存在或已过期，或者环境变量 NVIDIA_LICENSE_FILE 设置不正确，则可能会发生此错误。
                                          </p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>


### 2.2.3 cublasOperation_t
`cublasOperation_t `类型指示需要对密集矩阵执行哪个操作。 它的值对应于 Fortran 字符“N”或“n”（非转置）、“T”或“t”（转置）和“C”或“c”（共轭转置），这些字符通常用作传统 BLAS 的参数 实施。


|Value	|Meaning|
|----|----|
|CUBLAS_OP_N|选择非转置操作|
|CUBLAS_OP_T|转置操作被选中|
|CUBLAS_OP_C|共轭转置操作被选中|


#### 2.2.4 cublasFillMode_t
类型指示密集矩阵的哪一部分（下部或上部）被填充，因此应该由函数使用。 它的值对应于 Fortran 字符“L”或“l”（下）和“U”或“u”（上），这些字符通常用作传统 BLAS 实现的参数。

|Value	|Meaning|
|----|----|
|CUBLAS_FILL_MODE_LOWER|矩阵的下部被填充|
|CUBLAS_FILL_MODE_UPPER|矩阵的上半部分被填充|
|CUBLAS_FILL_MODE_FULL|整个矩阵被填充|


### 2.2.5 cublasDiagType_t
类型指示稠密矩阵的主对角线是否为单位，因此不应被函数触及或修改。 它的值对应于 Fortran 字符“N”或“n”（非单位）和“U”或“u”（单位），这些字符通常用作传统 BLAS 实现的参数。

|Value	|Meaning|
|----|----|
|CUBLAS_DIAG_NON_UNIT|矩阵对角线具有非单位元素|
|CUBLAS_DIAG_UNIT|矩阵对角线具有单位元素|



### 2.2.6 cublasSideMode_t
类型指示稠密矩阵在由特定函数求解的矩阵方程中是位于左侧还是右侧。 它的值对应于 Fortran 字符“L”或“l”（左）和“R”或“r”（右），这些字符通常用作传统 BLAS 实现的参数。
|Value	|Meaning|
|----|----|
|CUBLAS_SIDE_LEFT|矩阵在等式的左边|
|CUBLAS_SIDE_RIGHT|矩阵在等式的右边|

### 2.2.7 cublasPointerMode_t
`cublasPointerMode_t` 类型指示标量值是在主机还是设备上通过引用传递。 需要指出的是，如果函数调用中存在多个标量值，则它们都必须符合相同的单指针模式。 可以分别使用 `cublasSetPointerMode() `和 `cublasGetPointerMode()` 例程设置和检索指针模式。

|Value	|Meaning|
|----|----|
|CUBLAS_POINTER_MODE_HOST|标量在主机上通过引用传递|
|CUBLAS_POINTER_MODE_DEVICE|标量在设备上通过引用传递|

### 2.2.8 cublasAtomicsMode_t
该类型指示是否可以使用具有使用原子的替代实现的 cuBLAS 例程。 可以分别使用 `cublasSetAtomicsMode()` 和 `cublasGetAtomicsMode()` 和例程设置和查询原子模式。

|Value	|Meaning|
|----|----|
|CUBLAS_ATOMICS_NOT_ALLOWED|不允许使用原子|
|CUBLAS_ATOMICS_ALLOWED|允许使用原子|


### 2.2.9 cublasGemmAlgo_t
`cublasGemmAlgo_t` 类型是一个枚举数，用于指定 GPU 架构上的矩阵-矩阵乘法算法，最高 `sm_75`。 在 `sm_80` 和更新的 GPU 架构上，此 `enumarant` 无效。 cuBLAS 具有以下算法选项：

|Value	|Meaning|
|----|----|
|CUBLAS_GEMM_DEFAULT|应用启发式方法选择 GEMM 算法|
|CUBLAS_GEMM_ALGO0 to CUBLAS_GEMM_ALGO23|明确选择算法 [0,23]。 注意：对 NVIDIA Ampere 架构 GPU 和更新版本没有影响。|
|CUBLAS_GEMM_DEFAULT_TENSOR_OP[DEPRECATED]|此模式已弃用，将在未来版本中删除。 应用启发式方法来选择 GEMM 算法，同时允许使用降低精度的 CUBLAS_COMPUTE_32F_FAST_16F 内核（为了向后兼容）。|
|CUBLAS_GEMM_ALGO0_TENSOR_OP to CUBLAS_GEMM_ALGO15_TENSOR_OP[DEPRECATED]|这些值已弃用，将在未来版本中删除。 明确选择 Tensor 核心 GEMM 算法 [0,15]。 允许使用降低精度的 CUBLAS_COMPUTE_32F_FAST_16F 内核（为了向后兼容）。 注意：对 NVIDIA Ampere 架构 GPU 和更新版本没有影响。|

### 2.2.10 cublasMath_t
`cublasMath_t` 枚举类型在 `cublasSetMathMode()` 中用于选择如下定义的计算精度模式。 由于此设置不直接控制Tensor Core的使用，模式 `CUBLAS_TENSOR_OP_MATH` 已被弃用，并将在未来的版本中删除。


|Value	|Meaning|
|----|----|
|CUBLAS_DEFAULT_MATH|这是默认和最高性能模式，它使用计算和中间存储精度，并且尾数和指数位数至少与请求的位数相同。 将尽可能使用Tensor Core。|
|CUBLAS_PEDANTIC_MATH|此模式对计算的所有阶段使用规定的精度和标准化算法，主要用于数值稳健性研究、测试和调试。 此模式的性能可能不如其他模式。|
|CUBLAS_TF32_TENSOR_OP_MATH|使用 TF32 Tensor Core启用单精度例程加速。|
|CUBLAS_MATH_DISALLOW_REDUCED_PRECISION_REDUCTION|在输出类型精度小于计算类型精度的混合精度例程中，强制矩阵乘法期间的任何归约使用累加器类型（即计算类型）而不是输出类型。 这是一个可以与任何其他值一起设置（使用按位或运算）的标志。|
|CUBLAS_TENSOR_OP_MATH [DEPRECATED]|此模式已弃用，将在未来版本中删除。 允许库尽可能使用 Tensor Core 操作。 对于单精度 GEMM 例程，cuBLAS 将使用 CUBLAS_COMPUTE_32F_FAST_16F 计算类型。|

### 2.2.11 cublasComputeType_t
`cublasComputeType_t` 枚举类型用于 `cublasGemmEx` 和 `cublasLtMatmul`（包括所有批处理和跨步批处理变体）来选择如下定义的计算精度模式。

<div class="tablenoborder">
                              <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="50%" id="d195e2094" rowspan="1" colspan="1">
                                          Value  
                                       </th>
                                       <th class="entry" valign="top" width="50%" id="d195e2097" rowspan="1" colspan="1">
                                          Meaning 
                                       </th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_16F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 这是 16 位半精度浮点和所有至少具有 16 位半精度的计算和中间存储精度的默认和最高性能模式。 将尽可能使用Tensor Core。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_16F_PEDANTIC</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 此模式对所有计算阶段使用 16 位半精度浮点标准化算法，主要用于数值稳健性研究、测试和调试。 此模式的性能可能不如其他模式，因为它禁用了Tensor Core。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_32F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 这是默认的 32 位单精度浮点，并使用至少 32 位的计算和中间存储精度。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_32F_PEDANTIC</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 对所有计算阶段使用 32 位单精度浮点算法，并禁用算法优化，例如高斯复杂度降低 (3M)。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_32F_FAST_16F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 允许库将Tensor Core与自动下转换和 16 位半精度计算一起用于 32 位输入和输出矩阵。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_32F_FAST_16BF</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 允许库将Tensor Core与自动下转换和 bfloat16 计算一起用于 32 位输入和输出矩阵。 有关 bfloat16 的更多详细信息，请参阅备用浮点部分。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_32F_FAST_TF32</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 允许库将Tensor Core与 TF32 计算一起用于 32 位输入和输出矩阵。 有关 TF32 计算的更多详细信息，请参阅备用浮点部分。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_64F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 这是默认的 64 位双精度浮点，并使用至少 64 位的计算和中间存储精度。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_64F_PEDANTIC</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 对所有计算阶段使用 64 位双精度浮点算法，并禁用算法优化，例如高斯复杂度降低 (3M)。
                                          </p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_32I</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 这是默认的 32 位整数模式，并使用至少 32 位的计算和中间存储精度。</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2094" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_COMPUTE_32I_PEDANTIC</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2097" rowspan="1" colspan="1">
                                          <p class="p"> 对所有计算阶段使用 32 位整数运算。</p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>

**注意：**设置环境变量 `NVIDIA_TF32_OVERRIDE = 0` 将覆盖 NVIDIA 库的任何默认值或编程配置，因此，cuBLAS 不会使用 TF32 Tensor Core加速 FP32 计算。


## 2.3. CUDA 数据类型参考
本章描述了由多个 CUDA 库共享并在头文件 library_types.h 中定义的类型。

### 2.3.1 cudaDataType_t
`cudaDataType_t` 类型是用于指定数据精度的枚举数。 当数据引用本身不携带类型时使用它（例如 void *）

例如，它用于例程 `cublasSgemmEx`。

<div class="tablenoborder">
                              <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="50%" id="d195e2366" rowspan="1" colspan="1">
                                          Value
                                       </th>
                                       <th class="entry" valign="top" width="50%" id="d195e2369" rowspan="1" colspan="1">
                                          Meaning
                                       </th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_R_16F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 16 位实半精度浮点</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_C_16F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 16 位复数半精度浮点数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_R_16BF</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 16 位实数 bfloat16 浮点数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_C_16BF</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 16 位复数 bfloat16 浮点数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_R_32F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 32 位实数单精度浮点数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_C_32F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 32 位复数单精度浮点数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_R_64F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 64 位实数双精度浮点数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_C_64F</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 64 位复数双精度浮点数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_R_8I</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 8 位实数有符号整数r</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_C_8I</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 8 位复数有符号整数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_R_8U</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 8 位实数无符号整数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_C_8U</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 8 位复数无符号整数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_R_32I</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型是 32 位实数有符号整数</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e2366" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUDA_C_32I</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e2369" rowspan="1" colspan="1">
                                          <p class="p">数据类型为 32 位复数有符号整数</p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>

### 2.3.2. libraryPropertyType_t
`libraryPropertyType_t` 用作参数以指定在使用例程 `cublasGetProperty` 时请求哪个属性


|Value	|Meaning|
|----|----|
|MAJOR_VERSION|查询主要版本的枚举器|
|MINOR_VERSION|查询次要版本的枚举数|
|PATCH_LEVEL|标识补丁级别的编号|



## 2.4. cuBLAS Helper Function Reference

### 2.4.1. cublasCreate()

```c++
cublasStatus_t
cublasCreate(cublasHandle_t *handle)
```
此函数初始化 cuBLAS 库并创建一个指向包含 cuBLAS 库上下文的不透明结构的句柄。 它在主机和设备上分配硬件资源，并且必须在进行任何其他 cuBLAS 库调用之前调用。 cuBLAS 库上下文与当前的 CUDA 设备相关联。 **要在多个设备上使用该库，需要为每个设备创建一个 cuBLAS 句柄。** 此外，对于给定的设备，可以创建具有不同配置的多个 cuBLAS 手柄。 因为 `cublasCreate()` 分配了一些内部资源，调用 `cublasDestroy()` 释放这些资源会隐式调用 `cublasDeviceSynchronize()`，建议尽量减少 `cublasCreate()/cublasDestroy()` 的出现次数。 对于从不同线程使用相同设备的多线程应用程序，推荐的编程模型是为每个线程创建一个 cuBLAS 句柄，并在线程的整个生命周期中使用该 cuBLAS 句柄。



|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|初始化成功|
|CUBLAS_STATUS_NOT_INITIALIZED|CUDA™ 运行时初始化失败|
|CUBLAS_STATUS_ALLOC_FAILED|资源无法分配|
|CUBLAS_STATUS_INVALID_VALUE|handle == NULL|

### 2.4.2. cublasDestroy()
```c++
cublasStatus_t
cublasDestroy(cublasHandle_t handle)
```
此函数释放 cuBLAS 库使用的硬件资源。 这个函数通常是最后一次调用 cuBLAS 库的特定句柄。 因为 `cublasCreate()` 分配了一些内部资源，调用 `cublasDestroy()` 释放这些资源会隐式调用 `cublasDeviceSynchronize()`，建议尽量减少 `cublasCreate()/cublasDestroy()` 的出现次数。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|关闭成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|



### 2.4.3. cublasGetVersion()

```c++
cublasStatus_t
cublasGetVersion(cublasHandle_t handle, int *version)
```
此函数返回 cuBLAS 库的版本号。
|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|为库版本号提供的存储未初始化（NULL）|

### 2.4.4. cublasGetProperty()

```c++
cublasStatus_t
cublasGetProperty(libraryPropertyType type, int *value)
```

此函数返回 value 指向的内存中所请求属性的值。 有关支持的类型，请参阅 libraryPropertyType。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|类型值无效, 如果类型值无效或value == NULL|


### 2.4.5. cublasGetStatusName()
```c++
const char* cublasGetStatusName(cublasStatus_t status)
```
此函数返回给定状态的字符串表示形式。

|Return Value	|Meaning|
|----|----|
|NULL-terminated string|状态的字符串表示|

### 2.4.6. cublasGetStatusString()
```c++
const char* cublasGetStatusString(cublasStatus_t status)
```
此函数返回给定状态的描述字符串。
|Return Value	|Meaning|
|----|----|
|NULL-terminated string|状态描述|

### 2.4.7. cublasSetStream()
```c++
cublasStatus_t
cublasSetStream(cublasHandle_t handle, cudaStream_t streamId)
```
此函数设置 cuBLAS 库流，该流将用于执行对 cuBLAS 库函数的所有后续调用。 如果未设置 cuBLAS 库流，则所有内核都使用 defaultNULL 流。 特别是，此例程可用于更改内核启动之间的流，然后将 cuBLAS 库流重置回 NULL。 此外，此函数无条件地将 cuBLAS 库工作区重置回默认工作区池（请参阅 cublasSetWorkspace()）。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|流设置成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|

### 2.4.8. cublasSetWorkspace()

```c++
cublasStatus_t
cublasSetWorkspace(cublasHandle_t handle, void *workspace, size_t workspaceSizeInBytes)
```
此函数将 cuBLAS 库工作区设置为用户拥有的设备缓冲区，该缓冲区将用于执行对 cuBLAS 库函数的所有后续调用（在当前设置的流上）。如果未设置 cuBLAS 库工作空间，所有内核将使用在 cuBLAS 上下文创建期间分配的默认工作空间池。特别是，此例程可用于更改内核启动之间的工作空间。工作区指针必须至少对齐 256 字节，否则会返回 `CUBLAS_STATUS_INVALID_VALUE` 错误。 `cublasSetStream() `函数无条件地将 cuBLAS 库工作区重置回默认工作区池。太小的 `workspaceSizeInBytes` 可能会导致某些例程失败并返回 `CUBLAS_STATUS_ALLOC_FAILED` 错误或导致性能大幅下降。等于或大于 **16KiB** 的工作空间大小足以防止 `CUBLAS_STATUS_ALLOC_FAILED` 错误，而更大的工作空间可以为某些例程提供性能优势。用户提供的工作空间的推荐大小至少为 4MiB（以匹配 cuBLAS 的默认工作空间池）。


|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|流设置成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|工作区指针未与至少 256 字节对齐|


### 2.4.9. cublasGetStream()

```c++
cublasStatus_t
cublasGetStream(cublasHandle_t handle, cudaStream_t *streamId)
```

此函数获取 cuBLAS 库流，该流用于执行对 cuBLAS 库函数的所有调用。 如果未设置 cuBLAS 库流，则所有内核都使用 *default* NULL 流。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|流设置成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|streamId == NULL|


### 2.4.10. cublasGetPointerMode()

```c++
cublasStatus_t
cublasGetPointerMode(cublasHandle_t handle, cublasPointerMode_t *mode)
```
该函数获取cuBLAS库使用的指针模式。 有关更多详细信息，请参阅有关 `cublasPointerMode_t` 类型的部分。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|指针模式获取成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|mode == NULL|


### 2.4.11. cublasSetPointerMode()

```c++
cublasStatus_t
cublasSetPointerMode(cublasHandle_t handle, cublasPointerMode_t mode)
```
此函数设置 cuBLAS 库使用的指针模式。 默认值是通过主机上的引用传递的值。 有关更多详细信息，请参阅有关 `cublasPointerMode_t` 类型的部分。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|指针模式设置成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|模式不是 `CUBLAS_POINTER_MODE_HOST` 或 `CUBLAS_POINTER_MODE_DEVICE`|

### 2.4.12. cublasSetVector()

```c++
cublasStatus_t
cublasSetVector(int n, int elemSize,
                const void *x, int incx, void *y, int incy)
```
此函数将 n 个元素从主机内存空间中的向量 x 复制到 GPU 内存空间中的向量 y。 假定两个向量中的元素的大小为 `elemSize` 字节。 连续元素之间的存储间距由源向量 x 的 `incx` 和目标向量 y 的 `incy` 给出。

由于假定二维矩阵的列主要格式，如果向量是矩阵的一部分，则等于 1 的向量增量访问该矩阵的（部分）列。 类似地，使用等于矩阵前导维度的增量会导致访问该矩阵的（部分）行。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 incx, incy, elemSize<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|

### 2.4.13. cublasGetVector()

```c++
cublasStatus_t
cublasGetVector(int n, int elemSize,
                const void *x, int incx, void *y, int incy)
```
此函数将 n 个元素从 GPU 内存空间中的向量 x 复制到主机内存空间中的向量 y。 假定两个向量中的元素的大小为 elemSize 字节。 连续元素之间的存储间距由源向量的 incx 和目标向量 y 的 incy 给出。

由于假定二维矩阵的列主要格式，如果向量是矩阵的一部分，则等于 1 的向量增量访问该矩阵的（部分）列。 类似地，使用等于矩阵前导维度的增量会导致访问该矩阵的（部分）行。
|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 incx, incy, elemSize<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|



### 2.4.14. cublasSetMatrix()

```c++
cublasStatus_t
cublasSetMatrix(int rows, int cols, int elemSize,
                const void *A, int lda, void *B, int ldb)
```
此函数将主机内存空间中的矩阵 A 中的行 x cols 元素复制到 GPU 内存空间中的矩阵 B。 假设每个元素都需要存储 `elemSize` 字节，并且两个矩阵都以列优先格式存储，源矩阵 A 和目标矩阵 B 的前导维度分别在 lda 和 ldb 中给出。 前导维度指示分配矩阵的行数，即使仅使用它的子矩阵。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 rows, cols<0 或 elemSize, lda, ldb<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|

### 2.4.15. cublasGetMatrix()

```c++
cublasStatus_t
cublasGetMatrix(int rows, int cols, int elemSize,
                const void *A, int lda, void *B, int ldb)
```
此函数将 GPU 内存空间中的矩阵 A 中的行 x cols 元素复制到主机内存空间中的矩阵 B。 假设每个元素都需要存储 `elemSize `字节，并且两个矩阵都以列优先格式存储，源矩阵 A 和目标矩阵 B 的前导维度分别在 lda 和 ldb 中给出。 前导维度指示分配矩阵的行数，即使仅使用它的子矩阵。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 rows, cols<0 或 elemSize, lda, ldb<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|


### 2.4.16. cublasSetVectorAsync()

```c++
cublasStatus_t
cublasSetVectorAsync(int n, int elemSize, const void *hostPtr, int incx,
                     void *devicePtr, int incy, cudaStream_t stream)
```
此函数具有与 `cublasSetVector()` 相同的功能，不同之处在于数据传输是使用给定的 CUDA™ 流参数异步完成的（相对于主机）。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 incx, incy, elemSize<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|


### 2.4.17. cublasGetVectorAsync()
```c++
cublasStatus_t
cublasGetVectorAsync(int n, int elemSize, const void *devicePtr, int incx,
                     void *hostPtr, int incy, cudaStream_t stream)
```
此函数具有与 `cublasGetVector()` 相同的功能，不同之处在于数据传输是使用给定的 CUDA™ 流参数异步完成的（相对于主机）。
|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 incx, incy, elemSize<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|


### 2.4.18. cublasSetMatrixAsync()

```c++
cublasStatus_t
cublasSetMatrixAsync(int rows, int cols, int elemSize, const void *A,
                     int lda, void *B, int ldb, cudaStream_t stream)
```

此函数具有与 `cublasSetMatrix()` 相同的功能，不同之处在于数据传输是使用给定的 CUDA™ 流参数异步完成的（相对于主机）。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 rows, cols<0 或 elemSize, lda, ldb<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|


### 2.4.19. cublasGetMatrixAsync()

```c++
cublasStatus_t
cublasGetMatrixAsync(int rows, int cols, int elemSize, const void *A,
                     int lda, void *B, int ldb, cudaStream_t stream)
```
此函数具有与 `cublasGetMatrix()` 相同的功能，不同之处在于数据传输是使用给定的 CUDA™ 流参数异步完成的（相对于主机）。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_INVALID_VALUE|参数 rows, cols<0 或 elemSize, lda, ldb<=0|
|CUBLAS_STATUS_MAPPING_ERROR|访问 GPU 内存时出错|


### 2.4.20. cublasSetAtomicsMode()
```c++
cublasStatus_t cublasSetAtomicsMode(cublasHandlet handle, cublasAtomicsMode_t mode)
```
一些方法，如 `cublas<t>symv` 和 `cublas<t>hemv` 具有使用原子来累积结果的替代实现。 这种实现通常要快得多，但可以生成从一次运行到另一次运行的结果并不完全相同。 从数学上讲，这些不同的结果并不显着，但在调试这些差异时可能会产生偏见。

此函数允许或禁止在 cuBLAS 库中对所有具有替代实现的例程使用原子。 如果没有在任何 cuBLAS 例程的文档中明确指定，则意味着该例程没有使用原子的替代实现。 当原子模式被禁用时，当在同一硬件上使用相同的参数调用时，每个 cuBLAS 例程应该从一次运行到另一次运行产生相同的结果。

默认初始化的 `cublasHandle_t` 对象的默认原子模式是 `CUBLAS_ATOMICS_NOT_ALLOWED`。 有关详细信息，请参阅有关类型的部分。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|原子模式设置成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|


### 2.4.21. cublasGetAtomicsMode()

```c++
cublasStatus_t cublasGetAtomicsMode(cublasHandle_t handle, cublasAtomicsMode_t *mode)
```

此函数查询特定 cuBLAS 上下文的原子模式。

默认初始化的 `cublasHandle_t` 对象的默认原子模式是 `CUBLAS_ATOMICS_NOT_ALLOWED。` 有关详细信息，请参阅有关类型的部分。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|原子模式设置成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数模式是一个 NULL 指针|

### 2.4.22. cublasSetMathMode()

```c++
cublasStatus_t cublasSetMathMode(cublasHandle_t handle, cublasMath_t mode)
```

`cublasSetMathMode` 函数使您能够选择由 `cublasMath_t` 定义的计算精度模式（请参阅 [cublasMath_t](https://docs.nvidia.com/cuda/cublas/index.html#cublasmath_t)）。 允许用户将计算精度模式设置为它们的逻辑组合（不推荐使用的 `CUBLAS_TENSOR_OP_MATH` 除外）。 例如，`cublasSetMathMode(handle, CUBLAS_DEFAULT_MATH | CUBLAS_MATH_DISALLOW_REDUCED_PRECISION_REDUCTION)`。 请注意，默认的数学模式是 `CUBLAS_DEFAULT_MATH`。

有关 `cublasGemmEx()` 和 `cublasLtMatmul()` API 及其跨步变体允许的矩阵和计算精度，请参阅：[cublasGemmEx()](https://docs.nvidia.com/cuda/cublas/index.html#cublas-GemmEx)、[cublasGemmBatchedEx()](https://docs.nvidia.com/cuda/cublas/index.html#cublas-GemmBatchedEx)、[cublasGemmStridedBatchedEx()](https://docs.nvidia.com/cuda/cublas/index.html#cublas-GemmStridedBatchedEx) 和 [cublasLtMatmul()](https://docs.nvidia.com/cuda/cublas/index.html#cublasLtMatmul)。


|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|原子模式设置成功|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|指定了无效的模式值。|

### 2.4.23. cublasGetMathMode()
```c++
cublasStatus_t cublasGetMathMode(cublasHandle_t handle, cublasMath_t *mode)
```
此函数返回库例程使用的数学模式。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|数学类型成功返回。|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|模式为 NULL。|


### 2.4.24. cublasSetSmCountTarget()

```c++
cublasStatus_t cublasSetSmCountTarget(cublasHandle_t handle, int smCountTarget)
```

`cublasSetSmCountTarget` 函数允许在内核执行期间覆盖库可用的多处理器数量。

当已知 cuBLAS 例程与不同 CUDA 流上的其他工作同时运行时，此选项可用于提高库性能。 例如。 `NVIDIA A100 GPU` 有 108 个 SM，并且有一个并发 kenrel 运行，网格大小为 8，可以使用值为 100 的 `cublasSetSmCountTarget` 来覆盖库启发式算法，以优化在 100 个多处理器上运行。

当设置为 0 时，库将返回其默认行为。 输入值不应超过设备的多处理器计数，可使用 `cudaDeviceGetAttribute` 获取。 不接受负值。

用户在使用此例程修改库句柄时必须确保线程安全，类似于使用 `cublasSetStream` 时。

|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|SM 计数目标已成功设置。|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|`smCountTarget` 的值超出允许范围。|


### 2.4.25. cublasGetSmCountTarget()

```c++
cublasStatus_t cublasGetSmCountTarget(cublasHandle_t handle, int *smCountTarget)
```
此函数获取先前编程到库句柄的值。
|Return Value	|Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|SM 计数目标已成功设置。|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|`smCountTarget` 的值为NULL。|


### 2.4.26. cublasLoggerConfigure()
```c++
cublasStatus_t cublasLoggerConfigure(
    int             logIsOn,
    int             logToStdOut,
    int             logToStdErr,
    const char*     logFileName)
```
此函数在运行时配置日志记录。 除了这种类型的配置之外，还可以使用特殊的环境变量来配置日志记录，这些环境变量将由 libcublas 进行检查：

* **CUBLAS_LOGINFO_DBG**- 设置环境。 变量为“1”表示打开日志记录（默认情况下日志记录是关闭的）。
* **CUBLAS_LOGDEST_DBG** - 设置环境。 变量编码如何记录。 “stdout”、“stderr”分别表示将日志消息输出到stdout或stderr。 在另一种情况下，它指定文件的“文件名”。

**参数**

**logIsOn**
* 输入。 完全打开/关闭日志记录。 默认情况下是关闭的，但通过调用 `cublasSetLoggerCallback` 到用户定义的回调函数来打开。

**logToStdOut**
* 输入。 打开/关闭标准错误 I/O 流的日志记录。 默认情况下是关闭的。

**logToStdErr**
* 输入。 打开/关闭标准错误 I/O 流的日志记录。 默认情况下是关闭的。

**日志文件名**
* 输入。 打开/关闭日志记录到由其名称指定的文件系统中的文件。 `cublasLogger` 配置 `logFileName` 的拷贝内容。 如果您对这种类型的日志记录不感兴趣，您应该提供空指针。

**返回**

**CUBLAS_STATUS_SUCCESS**
* 成功。

### 2.4.27. cublasGetLoggerCallback()
```c++
cublasStatus_t cublasGetLoggerCallback(
    cublasLogCallback* userCallback)
```
此函数通过 `cublasSetLoggerCallback` 检索指向先前安装的自定义用户定义回调函数的函数指针，否则为零。

**参数**

**用户回调**
* 输出。 指向用户定义的回调函数的指针。

**返回**

**CUBLAS_STATUS_SUCCESS**
* 成功。


### 2.4.28. cublasSetLoggerCallback()

```c++
cublasStatus_t cublasSetLoggerCallback(
    cublasLogCallback   userCallback)
```
此函数通过 cublas C 公共 API 安装自定义用户定义的回调函数。

**参数**

**userCallback**
* 输入。 指向用户定义的回调函数的指针。

**返回值**

**CUBLAS_STATUS_SUCCESS**
* 成功。


## 2.5. cuBLAS Level-1 Function Reference

在本章中，我们描述了执行基于标量和向量的运算的 Level-1 基本线性代数子程序 (BLAS1) 函数。 我们将使用缩写 `<type>` 表示类型，使用 `<t>` 表示相应的短类型，以更简洁明了地表示实现的功能。 除非另有说明，`<type>` 和 `<t>` 的含义如下：



|`<type>`	|`<t>`	|Meaning|
|----|----|----|
|float|‘s’ or ‘S’|real single-precision|
|double|‘d’ or ‘D’|real double-precision|
|cuComplex|‘c’ or ‘C’|complex single-precision|
|cuDoubleComplex|‘z’ or ‘Z’|complex double-precision|

当函数的参数和返回值不同时，有时会出现复杂的输入，`<t>`也可以有以下含义“Sc”、“Cs”、“Dz”和“Zd”。

缩写 Re(.) 和 Im(.) 将分别代表数字的实部和虚部。 由于实数的虚部不存在，我们将其视为零，通常可以简单地将其从使用它的方程中丢弃。 此外，<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mover accent="true">
    <mrow>
      <mi>&#x3B1;</mi>
    </mrow>
    <mo class="MathClass-op">&#x304;</mo>
  </mover>
</math>将表示 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3B1;</mi>
</math>的复共轭。

一般来说，在整个文档中，小写希腊符号<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3B1;</mi>
</math>和<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>&#x3B2;</mi>
</math>将表示标量，以粗体表示的小写英文字母<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mstyle mathvariant="bold">
    <mi>x</mi>
  </mstyle>
</math>和<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mstyle mathvariant="bold">
    <mi>y</mi>
  </mstyle>
</math>，将表示向量和大写英文字母A, B和C，并将表示矩阵。

### 2.5.1. `cublasI<t>amax()`

此函数查找最大元素的（最小）索引。 因此，<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo class="MathClass-rel">|</mo>
  <mstyle mathvariant="bold">
    <mi>I</mi>
    <mi>m</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>x</mi>
      <mrow>
        <mo class="MathClass-open">[</mo>
        <mrow>
          <mi>j</mi>
        </mrow>
        <mo class="MathClass-close">]</mo>
      </mrow>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo class="MathClass-rel">|</mo>
  <mo class="MathClass-bin">+</mo>
  <mo class="MathClass-rel">|</mo>
  <mstyle mathvariant="bold">
    <mi>R</mi>
    <mi>e</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>x</mi>
      <mrow>
        <mo class="MathClass-open">[</mo>
        <mrow>
          <mi>j</mi>
        </mrow>
        <mo class="MathClass-close">]</mo>
      </mrow>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo class="MathClass-rel">|</mo>
</math>结果是第一个对于<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>i</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-punc">,</mo>
  <mo class="MathClass-op">&#x2026;</mo>
  <mo class="MathClass-punc">,</mo>
  <mi>n</mi>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>j</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-bin">+</mo>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>i</mi>
      <mo class="MathClass-bin">-</mo>
      <mn>1</mn>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo data-mjx-pseudoscript="true" class="MathClass-bin">*</mo>
  <mtext>&#xA0;incx</mtext>
</math>最大的结果。 请注意，最后一个等式反映了用于与 Fortran 兼容的基于 1 的索引。


|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with elements.|
|incx||input|stride between consecutive elements of x.|
|result|host or device|output|the resulting index, which is 0 if n,incx<=0|


该函数可能返回的错误值及其含义如下所列。



|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|无法分配缩减缓冲区|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考：

[isamax](http://www.netlib.org/blas/isamax.f), [idamax](http://www.netlib.org/blas/idamax.f), [icamax](http://www.netlib.org/blas/icamax.f), [izamax](http://www.netlib.org/blas/izamax.f)

### 2.5.2. `cublasI<t>amin()`
```c++
cublasStatus_t cublasIsamin(cublasHandle_t handle, int n,
                            const float *x, int incx, int *result)
cublasStatus_t cublasIdamin(cublasHandle_t handle, int n,
                            const double *x, int incx, int *result)
cublasStatus_t cublasIcamin(cublasHandle_t handle, int n,
                            const cuComplex *x, int incx, int *result)
cublasStatus_t cublasIzamin(cublasHandle_t handle, int n,
                            const cuDoubleComplex *x, int incx, int *result)
```
此函数查找最小元素的（最小）索引。 因此，<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mo class="MathClass-rel">|</mo>
  <mstyle mathvariant="bold">
    <mi>I</mi>
    <mi>m</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>x</mi>
      <mrow>
        <mo class="MathClass-open">[</mo>
        <mrow>
          <mi>j</mi>
        </mrow>
        <mo class="MathClass-close">]</mo>
      </mrow>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo class="MathClass-rel">|</mo>
  <mo class="MathClass-bin">+</mo>
  <mo class="MathClass-rel">|</mo>
  <mstyle mathvariant="bold">
    <mi>R</mi>
    <mi>e</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>x</mi>
      <mrow>
        <mo class="MathClass-open">[</mo>
        <mrow>
          <mi>j</mi>
        </mrow>
        <mo class="MathClass-close">]</mo>
      </mrow>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo class="MathClass-rel">|</mo>
</math>结果是第一个对于<math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>i</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-punc">,</mo>
  <mo class="MathClass-op">&#x2026;</mo>
  <mo class="MathClass-punc">,</mo>
  <mi>n</mi>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>j</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-bin">+</mo>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>i</mi>
      <mo class="MathClass-bin">-</mo>
      <mn>1</mn>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo data-mjx-pseudoscript="true" class="MathClass-bin">*</mo>
  <mtext>&#xA0;incx</mtext>
</math>最小的结果。 请注意，最后一个等式反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with elements.|
|incx||input|stride between consecutive elements of x.|
|result|host or device|output|the resulting index, which is 0 if n,incx<=0|

该函数可能返回的错误值及其含义如下所列。
|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|无法分配缩减缓冲区|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考：

[isamin](http://www.netlib.org/scilib/blass.f)


### 2.5.3. cublas<t>asum()

```c++
cublasStatus_t  cublasSasum(cublasHandle_t handle, int n,
                            const float           *x, int incx, float  *result)
cublasStatus_t  cublasDasum(cublasHandle_t handle, int n,
                            const double          *x, int incx, double *result)
cublasStatus_t cublasScasum(cublasHandle_t handle, int n,
                            const cuComplex       *x, int incx, float  *result)
cublasStatus_t cublasDzasum(cublasHandle_t handle, int n,
                            const cuDoubleComplex *x, int incx, double *result)
```

此函数计算向量 x 的元素的绝对值之和。 因此，结果是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <msubsup>
    <mrow>
      <mo class="MathClass-op">&#x2211;</mo>
    </mrow>
    <mrow>
      <mi>i</mi>
      <mo class="MathClass-rel">=</mo>
      <mn>1</mn>
    </mrow>
    <mrow>
      <mi>n</mi>
    </mrow>
  </msubsup>
  <mo class="MathClass-rel">|</mo>
  <mstyle mathvariant="bold">
    <mi>I</mi>
    <mi>m</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>x</mi>
      <mrow>
        <mo class="MathClass-open">[</mo>
        <mrow>
          <mi>j</mi>
        </mrow>
        <mo class="MathClass-close">]</mo>
      </mrow>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo class="MathClass-rel">|</mo>
  <mo class="MathClass-bin">+</mo>
  <mo class="MathClass-rel">|</mo>
  <mstyle mathvariant="bold">
    <mi>R</mi>
    <mi>e</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>x</mi>
      <mrow>
        <mo class="MathClass-open">[</mo>
        <mrow>
          <mi>j</mi>
        </mrow>
        <mo class="MathClass-close">]</mo>
      </mrow>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo class="MathClass-rel">|</mo>
</math> 其中 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>j</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-bin">+</mo>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>i</mi>
      <mo class="MathClass-bin">-</mo>
      <mn>1</mn>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo data-mjx-pseudoscript="true" class="MathClass-bin">*</mo>
  <mtext>&#xA0;incx</mtext>
</math> 。 请注意，最后一个等式反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with elements.|
|incx||input|stride between consecutive elements of x.|
|result|host or device|output|the resulting index, which is 0.0 if n,incx<=0|

该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|无法分配缩减缓冲区|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[sasum](http://www.netlib.org/blas/sasum.f), [dasum](http://www.netlib.org/blas/dasum.f), [scasum](http://www.netlib.org/blas/scasum.f), [dzasum](http://www.netlib.org/blas/dzasum.f)

### 2.5.4. cublas<t>axpy()
```c++
cublasStatus_t cublasSaxpy(cublasHandle_t handle, int n,
                           const float           *alpha,
                           const float           *x, int incx,
                           float                 *y, int incy)
cublasStatus_t cublasDaxpy(cublasHandle_t handle, int n,
                           const double          *alpha,
                           const double          *x, int incx,
                           double                *y, int incy)
cublasStatus_t cublasCaxpy(cublasHandle_t handle, int n,
                           const cuComplex       *alpha,
                           const cuComplex       *x, int incx,
                           cuComplex             *y, int incy)
cublasStatus_t cublasZaxpy(cublasHandle_t handle, int n,
                           const cuDoubleComplex *alpha,
                           const cuDoubleComplex *x, int incx,
                           cuDoubleComplex       *y, int incy)
```

此函数将向量 x 乘以标量并将其添加到向量 y 中，并用结果覆盖最新的向量。 因此，对 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>i</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-punc">,</mo>
  <mo class="MathClass-op">&#x2026;</mo>
  <mo class="MathClass-punc">,</mo>
  <mi>n</mi>
</math> 、 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>k</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-bin">+</mo>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>i</mi>
      <mo class="MathClass-bin">-</mo>
      <mn>1</mn>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo data-mjx-pseudoscript="true" class="MathClass-bin">*</mo>
  <mtext>&#xA0;incx</mtext>
</math> 和 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mi>j</mi>
  <mo class="MathClass-rel">=</mo>
  <mn>1</mn>
  <mo class="MathClass-bin">+</mo>
  <mrow>
    <mo class="MathClass-open">(</mo>
    <mrow>
      <mi>i</mi>
      <mo class="MathClass-bin">-</mo>
      <mn>1</mn>
    </mrow>
    <mo class="MathClass-close">)</mo>
  </mrow>
  <mo data-mjx-pseudoscript="true" class="MathClass-bin">*</mo>
  <mtext>&#xA0;incy</mtext>
</math> 执行的操作是 <math xmlns="http://www.w3.org/1998/Math/MathML">
  <mstyle mathvariant="bold">
    <mi>y</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">[</mo>
    <mrow>
      <mi>j</mi>
    </mrow>
    <mo class="MathClass-close">]</mo>
  </mrow>
  <mo class="MathClass-rel">=</mo>
  <mi>&#x3B1;</mi>
  <mo class="MathClass-bin">&#xD7;</mo>
  <mstyle mathvariant="bold">
    <mi>x</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">[</mo>
    <mrow>
      <mi>k</mi>
    </mrow>
    <mo class="MathClass-close">]</mo>
  </mrow>
  <mo class="MathClass-bin">+</mo>
  <mstyle mathvariant="bold">
    <mi>y</mi>
  </mstyle>
  <mrow>
    <mo class="MathClass-open">[</mo>
    <mrow>
      <mi>j</mi>
    </mrow>
    <mo class="MathClass-close">]</mo>
  </mrow>
</math>。 请注意，最后两个等式反映了用于与 Fortran 兼容的基于 1 的索引。



|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|in/out|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|无法分配缩减缓冲区|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[saxpy](http://www.netlib.org/blas/saxpy.f), [daxpy](http://www.netlib.org/blas/daxpy.f), [caxpy](http://www.netlib.org/blas/caxpy.f), [zaxpy](http://www.netlib.org/blas/zaxpy.f)


### 2.5.5. `cublas<t>copy()`

```c++
cublasStatus_t cublasScopy(cublasHandle_t handle, int n,
                           const float           *x, int incx,
                           float                 *y, int incy)
cublasStatus_t cublasDcopy(cublasHandle_t handle, int n,
                           const double          *x, int incx,
                           double                *y, int incy)
cublasStatus_t cublasCcopy(cublasHandle_t handle, int n,
                           const cuComplex       *x, int incx,
                           cuComplex             *y, int incy)
cublasStatus_t cublasZcopy(cublasHandle_t handle, int n,
                           const cuDoubleComplex *x, int incx,
                           cuDoubleComplex       *y, int incy)
```

该函数将向量 x 复制到向量 y 中。 因此，执行的操作是 y [ j ] = x [ k ] 对于 i = 1 , ... , n , k = 1 + ( i - 1 ) * incx 和 j = 1 + ( i - 1 ) * incy 。 请注意，最后两个等式反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|in/out|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|无法分配缩减缓冲区|


请参考:

[scopy](http://www.netlib.org/blas/scopy.f), [dcopy](http://www.netlib.org/blas/dcopy.f), [ccopy](http://www.netlib.org/blas/ccopy.f), [zcopy](http://www.netlib.org/blas/zcopy.f)

### 2.5.6. `cublas<t>dot()`

```c++
cublasStatus_t cublasSdot (cublasHandle_t handle, int n,
                           const float           *x, int incx,
                           const float           *y, int incy,
                           float           *result)
cublasStatus_t cublasDdot (cublasHandle_t handle, int n,
                           const double          *x, int incx,
                           const double          *y, int incy,
                           double          *result)
cublasStatus_t cublasCdotu(cublasHandle_t handle, int n,
                           const cuComplex       *x, int incx,
                           const cuComplex       *y, int incy,
                           cuComplex       *result)
cublasStatus_t cublasCdotc(cublasHandle_t handle, int n,
                           const cuComplex       *x, int incx,
                           const cuComplex       *y, int incy,
                           cuComplex       *result)
cublasStatus_t cublasZdotu(cublasHandle_t handle, int n,
                           const cuDoubleComplex *x, int incx,
                           const cuDoubleComplex *y, int incy,
                           cuDoubleComplex *result)
cublasStatus_t cublasZdotc(cublasHandle_t handle, int n,
                           const cuDoubleComplex *x, int incx,
                           const cuDoubleComplex *y, int incy,
                           cuDoubleComplex       *result)
```

此函数计算向量 x 和 y 的点积。 因此，结果是 ∑ i = 1 n ( x [ k ] × y [ j ] ) 其中 k = 1 + ( i - 1 ) * incx 和 j = 1 + ( i - 1 ) * incy 。 请注意，在第一个方程中，如果函数名称以字符“c”结尾，则应使用向量 x 的元素的共轭，并且最后两个方程反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|in/out|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|
|result|host or device|output|the resulting dot product, which is 0.0 if n<=0.|

该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|无法分配缩减缓冲区|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[sdot](http://www.netlib.org/blas/sdot.f), [ddot](http://www.netlib.org/blas/ddot.f), [cdotu](http://www.netlib.org/blas/cdotu.f), [cdotc](http://www.netlib.org/blas/cdotc.f), [zdotu](http://www.netlib.org/blas/zdotu.f), [zdotc](http://www.netlib.org/blas/zdotc.f)

### 2.5.7. `cublas<t>nrm2()`

```c++
cublasStatus_t  cublasSnrm2(cublasHandle_t handle, int n,
                            const float           *x, int incx, float  *result)
cublasStatus_t  cublasDnrm2(cublasHandle_t handle, int n,
                            const double          *x, int incx, double *result)
cublasStatus_t cublasScnrm2(cublasHandle_t handle, int n,
                            const cuComplex       *x, int incx, float  *result)
cublasStatus_t cublasDznrm2(cublasHandle_t handle, int n,
                            const cuDoubleComplex *x, int incx, double *result)
```

此函数计算向量 x 的欧几里得范数。 该代码使用累积的多阶段模型来避免中间下溢和上溢，结果等价于 ∑ i = 1 n ( x [ j ] × x [ j ] ) 其中 j = 1 + ( i - 1 ) * incx in 精确的算术。 请注意，最后一个等式反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|result|host or device|output|the resulting dot product, which is 0.0 if n<=0.|

该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|无法分配缩减缓冲区|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

### 2.5.8. `cublas<t>rot()`
```c++
cublasStatus_t  cublasSrot(cublasHandle_t handle, int n,
                           float           *x, int incx,
                           float           *y, int incy,
                           const float  *c, const float           *s)
cublasStatus_t  cublasDrot(cublasHandle_t handle, int n,
                           double          *x, int incx,
                           double          *y, int incy,
                           const double *c, const double          *s)
cublasStatus_t  cublasCrot(cublasHandle_t handle, int n,
                           cuComplex       *x, int incx,
                           cuComplex       *y, int incy,
                           const float  *c, const cuComplex       *s)
cublasStatus_t cublasCsrot(cublasHandle_t handle, int n,
                           cuComplex       *x, int incx,
                           cuComplex       *y, int incy,
                           const float  *c, const float           *s)
cublasStatus_t  cublasZrot(cublasHandle_t handle, int n,
                           cuDoubleComplex *x, int incx,
                           cuDoubleComplex *y, int incy,
                           const double *c, const cuDoubleComplex *s)
cublasStatus_t cublasZdrot(cublasHandle_t handle, int n,
                           cuDoubleComplex *x, int incx,
                           cuDoubleComplex *y, int incy,
                           const double *c, const double          *s)
```
此函数应用 Givens 旋转矩阵（即，在 x,y 平面中逆时针旋转由 cos(alpha)=c, sin(alpha)=s 定义的角度）：

G = c s - s c

到向量 x 和 y。

因此，结果是 x [ k ] = c × x [ k ] + s × y [ j ] 和 y [ j ] = - s × x [ k ] + c × y [ j ] 其中 k = 1 + ( i - 1 ) * incx 和 j = 1 + ( i - 1 ) * incy 。 请注意，最后两个等式反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|in/out|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|
|c|host or device|input|cosine element of the rotation matrix.|
|s|host or device|input|sine element of the rotation matrix.|

该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[srot](http://www.netlib.org/blas/srot.f), [drot](http://www.netlib.org/blas/drot.f), [crot](http://www.netlib.org/lapack/lapack_routine/crot.f), [csrot](http://www.netlib.org/blas/csrot.f), [zrot](http://www.netlib.org/lapack/lapack_routine/zrot.f), [zdrot](http://www.netlib.org/blas/zdrot.f)


### 2.5.9. `cublas<t>rotg()`
```c++
cublasStatus_t cublasSrotg(cublasHandle_t handle,
                           float           *a, float           *b,
                           float  *c, float           *s)
cublasStatus_t cublasDrotg(cublasHandle_t handle,
                           double          *a, double          *b,
                           double *c, double          *s)
cublasStatus_t cublasCrotg(cublasHandle_t handle,
                           cuComplex       *a, cuComplex       *b,
                           float  *c, cuComplex       *s)
cublasStatus_t cublasZrotg(cublasHandle_t handle,
                           cuDoubleComplex *a, cuDoubleComplex *b,
                           double *c, cuDoubleComplex *s)
```

此函数构造 Givens 旋转矩阵

G = c s - s c

将 2 × 1 向量 ( a , b ) T 的第二个条目归零。

然后，对于实数，我们可以写

c s - s c a b = r 0

其中 c 2 + s 2 = 1 和 r = a 2 + b 2 。 参数 a 和 b 分别被 r 和 z 覆盖。 z 的值使得 c 和 s 可以使用以下规则恢复：

( c , s ) = ( 1 - z 2 , z )  if  | z | < 1 ( 0 . 0 , 1 . 0 )  if  | z | = 1 ( 1 ∕ z , 1 - z 2 )  if  | z | > 1

对于复数，我们可以写

c s - s ̄ c a b = r 0

其中 c 2 + ( s ̄ × s ) = 1 and r = a | a | × || ( a , b ) T || 2 with || ( a , b ) T || 2 = | a | 2 + | b | 2 for a ≠ 0 and r = b for a = 0。 最后，参数 a 在退出时被 r 覆盖。


|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|a|host or device|in/out|`<type>` scalar that is overwritten with r .|
|b|host or device|in/out|`<type>` scalar that is overwritten with z .|
|c|host or device|input|cosine element of the rotation matrix.|
|s|host or device|input|sine element of the rotation matrix.|


|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[srotg](http://www.netlib.org/blas/srotg.f), [drotg](http://www.netlib.org/blas/drotg.f), [crotg](http://www.netlib.org/blas/crotg.f), [zrotg](http://www.netlib.org/blas/zrotg.f)

### 2.5.10. `cublas<t>rotm()`

```c++
cublasStatus_t cublasSrotm(cublasHandle_t handle, int n, float  *x, int incx,
                           float  *y, int incy, const float*  param)
cublasStatus_t cublasDrotm(cublasHandle_t handle, int n, double *x, int incx,
                           double *y, int incy, const double* param)
```
此函数应用修改后的 Givens 变换

H = h 1 1 h 1 2 h 2 1 h 2 2

到向量 x 和 y。

因此，结果是 x [ k ] = h 1 1 × x [ k ] + h 1 2 × y [ j ] 和 y [ j ] = h 2 1 × x [ k ] + h 2 2 × y [ j ] 其中 k = 1 + ( i - 1 ) * incx 和 j = 1 + ( i - 1 ) * incy 。 请注意，最后两个等式反映了用于与 Fortran 兼容的基于 1 的索引。

矩阵 H 的元素 、 和 分别存储在 param[1]、param[2]、param[3] 和 param[4] 中。 flag=param[0] 为矩阵 H 项定义以下预定义值


|flag=-1.0|	flag= 0.0|	flag= 1.0	|flag=-2.0|
|----|----|----|----|
|h 1 1 h 1 2 h 2 1 h 2 2|1 . 0 h 1 2 h 2 1 1 . 0|h 1 1 1 . 0 - 1 . 0 h 2 2|1 . 0 0 . 0 0 . 0 1 . 0|

请注意，标志所隐含的值 -1.0、0.0 和 1.0 未存储在 param 中。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|in/out|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|
|param|host or device|input|`<type>` vector of 5 elements, where param[0] and param[1-4] contain the flag and matrix H .|


该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[srotm](http://www.netlib.org/blas/srotm.f), [drotm](http://www.netlib.org/blas/drotm.f)

### 2.5.11. `cublas<t>rotmg()`

```c++
cublasStatus_t cublasSrotmg(cublasHandle_t handle, float  *d1, float  *d2,
                            float  *x1, const float  *y1, float  *param)
cublasStatus_t cublasDrotmg(cublasHandle_t handle, double *d1, double *d2,
                            double *x1, const double *y1, double *param)
```
此函数构造修改后的 Givens 变换

H = h 1 1 h 1 2 h 2 1 h 2 2

将 2 × 1 向量 (d 1 * x 1 , d 2 * y 1 ) T 的第二个条目归零。

`flag=param[0]` 为矩阵 H 项定义以下预定义值

|flag=-1.0|	flag= 0.0|	flag= 1.0	|flag=-2.0|
|----|----|----|----|
|h 1 1 h 1 2 h 2 1 h 2 2|1 . 0 h 1 2 h 2 1 1 . 0|h 1 1 1 . 0 - 1 . 0 h 2 2|1 . 0 0 . 0 0 . 0 1 . 0|


|Param.|	Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|d1|host or device|in/out|`<type>` scalar that is overwritten on exit.|
|d2|host or device|in/out|`<type>` scalar that is overwritten on exit.|
|x1|host or device|in/out|`<type>` scalar that is overwritten on exit.|
|y1|host or device|input|`<type>` scalar.|
|param|host or device|output|`<type>` vector of 5 elements, where param[0] and param[1-4] contain the flag and matrix H .|

该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[srotmg](http://www.netlib.org/blas/srotmg.f), [drotmg](http://www.netlib.org/blas/drotmg.f)


### 2.5.12. `cublas<t>scal()`

```bash
cublasStatus_t  cublasSscal(cublasHandle_t handle, int n,
                            const float           *alpha,
                            float           *x, int incx)
cublasStatus_t  cublasDscal(cublasHandle_t handle, int n,
                            const double          *alpha,
                            double          *x, int incx)
cublasStatus_t  cublasCscal(cublasHandle_t handle, int n,
                            const cuComplex       *alpha,
                            cuComplex       *x, int incx)
cublasStatus_t cublasCsscal(cublasHandle_t handle, int n,
                            const float           *alpha,
                            cuComplex       *x, int incx)
cublasStatus_t  cublasZscal(cublasHandle_t handle, int n,
                            const cuDoubleComplex *alpha,
                            cuDoubleComplex *x, int incx)
cublasStatus_t cublasZdscal(cublasHandle_t handle, int n,
                            const double          *alpha,
                            cuDoubleComplex *x, int incx)
```

该函数通过标量 α 缩放向量 x 并用结果覆盖它。 因此，执行的操作是 x [ j ] = α × x [ j ] 对于 i = 1 , ... , n 和 j = 1 + ( i - 1) *incx。 请注意，最后两个等式反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|

该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[sscal](http://www.netlib.org/blas/sscal.f), [dscal](http://www.netlib.org/blas/dscal.f), [csscal](http://www.netlib.org/blas/csscal.f), [cscal](http://www.netlib.org/blas/cscal.f), [zdscal](http://www.netlib.org/blas/zdscal.f), [zscal](http://www.netlib.org/blas/zscal.f)

### 2.5.13. `cublas<t>swap()`

```c++
cublasStatus_t cublasSswap(cublasHandle_t handle, int n, float           *x,
                           int incx, float           *y, int incy)
cublasStatus_t cublasDswap(cublasHandle_t handle, int n, double          *x,
                           int incx, double          *y, int incy)
cublasStatus_t cublasCswap(cublasHandle_t handle, int n, cuComplex       *x,
                           int incx, cuComplex       *y, int incy)
cublasStatus_t cublasZswap(cublasHandle_t handle, int n, cuDoubleComplex *x,
                           int incx, cuDoubleComplex *y, int incy)
```
此函数交换向量 x 和 y 的元素。 因此，执行的操作是 y [ j ] ⇔ x [ k ] 对于 i = 1 , ... , n , k = 1 + ( i - 1 ) * incx 和 j = 1 + ( i - 1 ) * incy 。 请注意，最后两个等式反映了用于与 Fortran 兼容的基于 1 的索引。

|Param.	|Memory|	In/out	|Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|n||input|number of elements in the vector x.|
|x|device|input|`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|in/out|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|

该函数可能返回的错误值及其含义如下所列。

|Error Value|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[sswap](http://www.netlib.org/blas/sswap.f), [dswap](http://www.netlib.org/blas/dswap.f), [cswap](http://www.netlib.org/blas/cswap.f), [zswap](http://www.netlib.org/blas/zswap.f)


## 2.6. cuBLAS Level-2 函数参考
在本章中，我们将描述执行矩阵向量运算的 Level-2 基本线性代数子程序 (BLAS2) 函数。

### 2.6.1. `cublas<t>gbmv()`

```c++
cublasStatus_t cublasSgbmv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n, int kl, int ku,
                           const float           *alpha,
                           const float           *A, int lda,
                           const float           *x, int incx,
                           const float           *beta,
                           float           *y, int incy)
cublasStatus_t cublasDgbmv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n, int kl, int ku,
                           const double          *alpha,
                           const double          *A, int lda,
                           const double          *x, int incx,
                           const double          *beta,
                           double          *y, int incy)
cublasStatus_t cublasCgbmv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n, int kl, int ku,
                           const cuComplex       *alpha,
                           const cuComplex       *A, int lda,
                           const cuComplex       *x, int incx,
                           const cuComplex       *beta,
                           cuComplex       *y, int incy)
cublasStatus_t cublasZgbmv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n, int kl, int ku,
                           const cuDoubleComplex *alpha,
                           const cuDoubleComplex *A, int lda,
                           const cuDoubleComplex *x, int incx,
                           const cuDoubleComplex *beta,
                           cuDoubleComplex *y, int incy)
```

此函数执行带状矩阵向量乘法

$y=\alpha op(A)x + \beta y$

其中 A 是具有 kl 次对角线和 ku 超对角线的带状矩阵，x 和 y 是向量，$\alpha$ 和 $\beta$ 是标量。 此外，对于矩阵 A:

$$
op(A)=
\begin{cases}
A\ \ \ \ 如果 transa == CUBLAS\_OP\_N,\\
A^T \ \ 如果 transa == CUBLAS\_OP\_T,\\
A^H \ \ 如果 transa == CUBLAS\_OP\_H
\end{cases}
$$

带状矩阵 A 逐列存储，主对角线存储在 ku+1 行（从第一个位置开始），第一个上对角线存储在 ku 行（从第二个位置开始），第一个子对角线存储在 ku+2 行 （从第一个位置开始）等等。所以一般来说，元素 A(i,j) 存储在内存位置 A(ku+1+i-j,j) 中，因为 j=1,...,n 和 $i\in[max(1,j-ku), min(m, j+kl)]$ . 此外，数组 A 中的元素在概念上不对应于带状矩阵中的元素（左上角 ku * ku 和右下角 kl *kl 三角形）不被引用。



|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|trans||input|operation op(A) that is non- or (conj.) transpose.|
|m||input|number of rows of matrix A.|
|n||input|number of columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|A|device|input|	`<type>` array of dimension lda x n with lda >= max(1,m). Before entry, the leading m by n part of the array A must contain the matrix of coefficients. Unchanged on exit.|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|`<type>` vector with n elements if transa == CUBLAS_OP_N and m elements otherwise.|
|incx||input|stride between consecutive elements of x.|
|beta|host or device|input|`<type>` scalar used for multiplication, if beta == 0 then y does not have to be a valid input.|
|y|device|in/out|`<type>` vector with m elements if transa == CUBLAS_OP_N and n elements otherwise.|
|incy||input|stride between consecutive elements of y.|

该函数可能返回的错误值及其含义如下所列。
<div class="tablenoborder">
                              <table cellpadding="4" cellspacing="0" summary="" class="table" frame="border" border="1" rules="all">
                                 <thead class="thead" align="left">
                                    <tr class="row">
                                       <th class="entry" valign="top" width="50%" id="d195e14174" rowspan="1" colspan="1">
                                          Error Value
                                       </th>
                                       <th class="entry" valign="top" width="50%" id="d195e14177" rowspan="1" colspan="1">
                                          Meaning 
                                       </th>
                                    </tr>
                                 </thead>
                                 <tbody class="tbody">
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e14174" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_SUCCESS</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e14177" rowspan="1" colspan="1">
                                          <p class="p">操作成功完成</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e14174" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_NOT_INITIALIZED</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e14177" rowspan="1" colspan="1">
                                          <p class="p">库未初始化</p>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e14174" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_INVALID_VALUE</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e14177" rowspan="1" colspan="1"><a name="cublas-lt-t-gt-gbmv__ul_urf_8bw_zfb" shape="rect">
                                             <!-- --></a><ul class="ul" id="cublas-lt-t-gt-gbmv__ul_urf_8bw_zfb">
                                             <li dir="ltr" class="li">
                                                <p dir="ltr" class="p">If <samp class="ph codeph">m, n, kl, ku &lt; 0</samp> or
                                                </p>
                                             </li>
                                             <li dir="ltr" class="li">
                                                <p dir="ltr" class="p">if <samp class="ph codeph">lda &lt; (kl+ku+1)</samp> or
                                                </p>
                                             </li>
                                             <li dir="ltr" class="li">
                                                <p dir="ltr" class="p">if <samp class="ph codeph">incx, incy == 0</samp> or
                                                </p>
                                             </li>
                                             <li dir="ltr" class="li">
                                                <p dir="ltr" class="p">if <samp class="ph codeph">trans</samp> != CUBLAS_OP_N, CUBLAS_OP_T, CUBLAS_OP_C or
                                                </p>
                                             </li>
                                             <li dir="ltr" class="li">
                                                <p dir="ltr" class="p"><samp class="ph codeph">alpha, beta == NULL</samp></p>
                                             </li>
                                          </ul>
                                       </td>
                                    </tr>
                                    <tr class="row">
                                       <td class="entry" valign="top" width="50%" headers="d195e14174" rowspan="1" colspan="1">
                                          <p class="p"><samp class="ph codeph">CUBLAS_STATUS_EXECUTION_FAILED</samp></p>
                                       </td>
                                       <td class="entry" valign="top" width="50%" headers="d195e14177" rowspan="1" colspan="1">
                                          <p class="p">该功能无法在 GPU 上启动</p>
                                       </td>
                                    </tr>
                                 </tbody>
                              </table>
                           </div>

请参考:
[sgbmv](http://www.netlib.org/blas/sgbmv.f), [dgbmv](http://www.netlib.org/blas/dgbmv.f), [cgbmv](http://www.netlib.org/blas/cgbmv.f), [zgbmv](http://www.netlib.org/blas/zgbmv.f)


### 2.6.2. `cublas<t>gemv()`

```c++
cublasStatus_t cublasSgemv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n,
                           const float           *alpha,
                           const float           *A, int lda,
                           const float           *x, int incx,
                           const float           *beta,
                           float           *y, int incy)
cublasStatus_t cublasDgemv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n,
                           const double          *alpha,
                           const double          *A, int lda,
                           const double          *x, int incx,
                           const double          *beta,
                           double          *y, int incy)
cublasStatus_t cublasCgemv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n,
                           const cuComplex       *alpha,
                           const cuComplex       *A, int lda,
                           const cuComplex       *x, int incx,
                           const cuComplex       *beta,
                           cuComplex       *y, int incy)
cublasStatus_t cublasZgemv(cublasHandle_t handle, cublasOperation_t trans,
                           int m, int n,
                           const cuDoubleComplex *alpha,
                           const cuDoubleComplex *A, int lda,
                           const cuDoubleComplex *x, int incx,
                           const cuDoubleComplex *beta,
                           cuDoubleComplex *y, int incy)
```

此函数执行矩阵向量乘法

$y=\alpha op(A)x + \beta y$

其中 A 是以列优先格式存储的 m*n 矩阵，x 和 y 是向量，$\alpha$ 和 $\beta$ 是标量。 此外，对于矩阵 A:

$$
op(A)=
\begin{cases}
A\ \ \ \ 如果 transa == CUBLAS\_OP\_N,\\
A^T \ \ 如果 transa == CUBLAS\_OP\_T,\\
A^H \ \ 如果 transa == CUBLAS\_OP\_H
\end{cases}
$$

|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|trans||input|operation op(A) that is non- or (conj.) transpose.|
|m||input|number of rows of matrix A.|
|n||input|number of columns of matrix A.|
|kl||input|number of subdiagonals of matrix A.|
|ku||input|number of superdiagonals of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|A|device|input|`<type>` array of dimension lda x n with lda>=kl+ku+1.|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|`<type>` vector with n elements if transa == CUBLAS_OP_N and m elements otherwise.|
|incx||input|stride between consecutive elements of x.|
|beta|host or device|input|`<type>` scalar used for multiplication, if beta == 0 then y does not have to be a valid input.|
|y|device|in/out|	`<type>` vector at least (1+(m-1)\*abs(incy)) elements if transa==CUBLAS_OP_N and at least (1+(n-1)*abs(incy)) elements otherwise.|
|incy||input|stride between consecutive elements of y.|

该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

### 2.6.3. `cublas<t>ger()`

```c++
cublasStatus_t  cublasSger(cublasHandle_t handle, int m, int n,
                           const float           *alpha,
                           const float           *x, int incx,
                           const float           *y, int incy,
                           float           *A, int lda)
cublasStatus_t  cublasDger(cublasHandle_t handle, int m, int n,
                           const double          *alpha,
                           const double          *x, int incx,
                           const double          *y, int incy,
                           double          *A, int lda)
cublasStatus_t cublasCgeru(cublasHandle_t handle, int m, int n,
                           const cuComplex       *alpha,
                           const cuComplex       *x, int incx,
                           const cuComplex       *y, int incy,
                           cuComplex       *A, int lda)
cublasStatus_t cublasCgerc(cublasHandle_t handle, int m, int n,
                           const cuComplex       *alpha,
                           const cuComplex       *x, int incx,
                           const cuComplex       *y, int incy,
                           cuComplex       *A, int lda)
cublasStatus_t cublasZgeru(cublasHandle_t handle, int m, int n,
                           const cuDoubleComplex *alpha,
                           const cuDoubleComplex *x, int incx,
                           const cuDoubleComplex *y, int incy,
                           cuDoubleComplex *A, int lda)
cublasStatus_t cublasZgerc(cublasHandle_t handle, int m, int n,
                           const cuDoubleComplex *alpha,
                           const cuDoubleComplex *x, int incx,
                           const cuDoubleComplex *y, int incy,
                           cuDoubleComplex *A, int lda)
```

此函数执行 rank-1 更新

$y=\alpha op(A)x + \beta y$



$$
A=
\begin{cases}
\alpha xy^T+A \ \ 如果ger(),geru()被调用\\
\alpha xy^H+A \ \ 如果 gerc()被调用
\end{cases}
$$

其中 A 是以列优先格式存储的 m*n 矩阵，x 和 y 是向量，$\alpha$是标量。 


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|m||input|number of rows of matrix A.|
|n||input|number of columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|A|device|input|	`<type>` array of dimension lda x n with lda >= max(1,m).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|`<type>` vector with n elements if transa == CUBLAS_OP_N and m elements otherwise.|
|incx||input|stride between consecutive elements of x.|
|y|device|in/out|	`<type>` vector at least (1+(m-1)\*abs(incy)) elements if transa==CUBLAS_OP_N and at least (1+(n-1)*abs(incy)) elements otherwise.|
|incy||input|stride between consecutive elements of y.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[sger](http://www.netlib.org/blas/sger.f), [dger](http://www.netlib.org/blas/dger.f), [cgeru](http://www.netlib.org/blas/cgeru.f), [cgerc](http://www.netlib.org/blas/cgerc.f), [zgeru](http://www.netlib.org/blas/zgeru.f), [zgerc](http://www.netlib.org/blas/zgerc.f)

### 2.6.4. `cublas<t>sbmv()`
```c++
cublasStatus_t cublasSsbmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, int k, const float  *alpha,
                           const float  *A, int lda,
                           const float  *x, int incx,
                           const float  *beta, float *y, int incy)
cublasStatus_t cublasDsbmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, int k, const double *alpha,
                           const double *A, int lda,
                           const double *x, int incx,
                           const double *beta, double *y, int incy)
```

此函数执行对称带状矩阵向量乘法:

$y = \alpha Ax+\beta y$

其中 A 是具有 k 个子对角线和超对角线的 n*n 对称带状矩阵，并且是向量，x 和 y 是标量。


如果 `uplo == CUBLAS_FILL_MODE_LOWER` 则对称带状矩阵 A 逐列存储，矩阵的主对角线存储在第 1 行，第 2 行的第一个下对角线（从第一个位置开始），第 3 行的第二个下对角线（开始 在第一个位置）等。因此，一般来说，元素 A(i,j) 存储在内存位置 A(1+i-j,j) 中 i=1,...,n 和 $i \in[j,min(m,j+k)]$ 。 此外，在概念上不对应于带状矩阵（右下角 k*k 三角形）中的元素的数组 A 中的元素不被引用。


如果 `uplo == CUBLAS_FILL_MODE_UPPER` 则对称带状矩阵 A 逐列存储，矩阵的主对角线存储在第 k+1 行，第 k 行的第一个下对角线（从第一个位置开始），第 k-1 行的第二个下对角线（开始 在第一个位置）等。因此，一般来说，元素 A(1+k+i-j,j) 存储在内存位置 A(1+i-j,j) 中 i=1,...,n 和 $i \in[max(1,j-k),j]$ 。 此外，在概念上不对应于带状矩阵（右下角 k*k 三角形）中的元素的数组 A 中的元素不被引用。


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|n||input|number of rows and columns of matrix A.|
|k||input|	number of sub- and super-diagonals of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|A|device|input|	`<type>` array of dimension lda x n with lda >= max(1,m).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|`<type>` vector with n elements if transa == CUBLAS_OP_N and m elements otherwise.|
|incx||input|stride between consecutive elements of x.|
|beta|host or device|input|`<type>` scalar used for multiplication, if beta==0 then y does not have to be a valid input.|
|y|device|in/out|	`<type>` vector at least (1+(m-1)\*abs(incy)) elements if transa==CUBLAS_OP_N and at least (1+(n-1)*abs(incy)) elements otherwise.|
|incy||input|stride between consecutive elements of y.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[ssbmv](http://www.netlib.org/blas/ssbmv.f), [dsbmv](http://www.netlib.org/blas/dsbmv.f)


### 2.6.5. `cublas<t>spmv()`

```c++
cublasStatus_t cublasSspmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const float  *alpha, const float  *AP,
                           const float  *x, int incx, const float  *beta,
                           float  *y, int incy)
cublasStatus_t cublasDspmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const double *alpha, const double *AP,
                           const double *x, int incx, const double *beta,
                           double *y, int incy)
```

此函数执行对称带状矩阵向量乘法:

$y = \alpha Ax+\beta y$

其中 A 是具有 k 个子对角线和超对角线的 n*n 对称带状矩阵，并且是向量，x 和 y 是标量。


如果 `uplo == CUBLAS_FILL_MODE_LOWER` 则对称矩阵 a 的下三角部分中的元素被逐列填充在一起，没有间隙。因此，一般来说，元素 A(i,j) 存储在内存位置 `AP[i+((2*n-j+1)*j)/2]` 中 j=1,...,n 和 $i>j$ 。 因此，打包格式只需要存储$\frac{n(n+1)}{2}$个元素。


如果 `uplo == CUBLAS_FILL_MODE_UPPER` 则对称矩阵 a 的下三角部分中的元素被逐列填充在一起，没有间隙.。因此，一般来说，元素 A(i,j) 存储在内存位置 `AP[i+(j*(j+1))/2]` 中 j=1,...,n 和 $i <= j$ 。 因此，打包格式只需要存储$\frac{n(n+1)}{2}$个元素。

|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|n||input|number of rows and columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|AP|device|input|	`<type>` array with  stored in packed format.|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|beta|host or device|input|`<type>` scalar used for multiplication, if beta==0 then y does not have to be a valid input.|
|y|device|in/out|	`<type>` vector at least (1+(m-1)\*abs(incy)) elements if transa==CUBLAS_OP_N and at least (1+(n-1)*abs(incy)) elements otherwise.|
|incy||input|stride between consecutive elements of y.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[sspmv](http://www.netlib.org/blas/sspmv.f), [dspmv](http://www.netlib.org/blas/dspmv.f)

### 2.6.6. `cublas<t>spr()`

```c++
cublasStatus_t cublasSspr(cublasHandle_t handle, cublasFillMode_t uplo,
                          int n, const float  *alpha,
                          const float  *x, int incx, float  *AP)
cublasStatus_t cublasDspr(cublasHandle_t handle, cublasFillMode_t uplo,
                          int n, const double *alpha,
                          const double *x, int incx, double *AP)
```
此函数执行对称带状矩阵向量乘法:

$y = \alpha xx^T+A$


其中 A 是以压缩格式存储的 n*n 对称矩阵，x 是向量，而 $\alpha$ 是标量。

如果 uplo == CUBLAS_FILL_MODE_LOWER 则对称矩阵 a 的下三角部分中的元素被逐列填充在一起，没有间隙. 因此，一般来说，元素 A(i,j) 存储在内存位置 `AP[i+((2*n-j+1)*j)/2]` 中 j=1,...,n 和 $i >= j$ 。 因此，打包格式只需要存储$\frac{n(n+1)}{2}$个元素。


如果 uplo == CUBLAS_FILL_MODE_UPPER 则对称矩阵 a 的下三角部分中的元素被逐列填充在一起，没有间隙. 因此，一般来说，元素 A(i,j) 存储在内存位置 `AP[i+(j*(j+1))/2]` 中 j=1,...,n 和 $i <= j$ 。 因此，打包格式只需要存储$\frac{n(n+1)}{2}$个元素。


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|n||input|number of rows and columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|AP|device|input|	`<type>` array with  stored in packed format.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|




该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[sspr](http://www.netlib.org/blas/sspr.f), [dspr](http://www.netlib.org/blas/dspr.f)


### `2.6.7. cublas<t>spr2()`
```c++
cublasStatus_t cublasSspr2(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const float  *alpha,
                           const float  *x, int incx,
                           const float  *y, int incy, float  *AP)
cublasStatus_t cublasDspr2(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const double *alpha,
                           const double *x, int incx,
                           const double *y, int incy, double *AP)
```
此函数执行打包的对称 rank-2 更新

$y = \alpha (xy^T + yx^T)+A$


其中 A 是以压缩格式存储的 n*n 对称矩阵，x 是向量，而 $\alpha$ 是标量。

如果 uplo == CUBLAS_FILL_MODE_LOWER 则对称矩阵 a 的下三角部分中的元素被逐列填充在一起，没有间隙. 因此，一般来说，元素 A(i,j) 存储在内存位置 `AP[i+((2*n-j+1)*j)/2]` 中 j=1,...,n 和 $i >= j$ 。 因此，打包格式只需要存储$\frac{n(n+1)}{2}$个元素。


如果 uplo == CUBLAS_FILL_MODE_UPPER 则对称矩阵 a 的下三角部分中的元素被逐列填充在一起，没有间隙. 因此，一般来说，元素 A(i,j) 存储在内存位置 `AP[i+(j*(j+1))/2]` 中 j=1,...,n 和 $i <= j$ 。 因此，打包格式只需要存储$\frac{n(n+1)}{2}$个元素。


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|n||input|number of rows and columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|AP|device|input|	`<type>` array with A stored in packed format.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|input|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|



该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[sspr2](http://www.netlib.org/blas/sspr2.f), [dspr2](http://www.netlib.org/blas/dspr2.f)


### `2.6.8. cublas<t>symv()`
```c++
cublasStatus_t cublasSsymv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const float           *alpha,
                           const float           *A, int lda,
                           const float           *x, int incx, const float           *beta,
                           float           *y, int incy)
cublasStatus_t cublasDsymv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const double          *alpha,
                           const double          *A, int lda,
                           const double          *x, int incx, const double          *beta,
                           double          *y, int incy)
cublasStatus_t cublasCsymv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const cuComplex       *alpha, /* host or device pointer */
                           const cuComplex       *A, int lda,
                           const cuComplex       *x, int incx, const cuComplex       *beta,
                           cuComplex       *y, int incy)
cublasStatus_t cublasZsymv(cublasHandle_t handle, cublasFillMode_t uplo,
                           int n, const cuDoubleComplex *alpha,
                           const cuDoubleComplex *A, int lda,
                           const cuDoubleComplex *x, int incx, const cuDoubleComplex *beta,
                           cuDoubleComplex *y, int incy)
```

此函数执行对称矩阵向量乘法。

$y = \alpha Ax+\beta y$

其中 A 是以低模式或高模式存储的 n*n 对称矩阵，x 和y 是向量，而 $\alpha$ 和 $\beta$是标量。

这个函数有另一个更快的实现，它使用可以通过 `cublasSetAtomicsMode()` 启用的原子。

请参阅函数 `cublasSetAtomicsMode()` 部分了解有关原子使用的更多详细信息。


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|n||input|number of rows and columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|A|device|input|`<type>` array of dimension lda x n with lda>=max(1,n).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|beta|host or device|input|<type> scalar used for multiplication, if beta==0 then y does not have to be a valid input.|
|y|device|input|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|



该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[ssymv](http://www.netlib.org/blas/ssymv.f), [dsymv](http://www.netlib.org/blas/dsymv.f)


### 2.6.9. `cublas<t>syr()`

```c++
cublasStatus_t cublasSsyr(cublasHandle_t handle, cublasFillMode_t uplo,
                          int n, const float           *alpha,
                          const float           *x, int incx, float           *A, int lda)
cublasStatus_t cublasDsyr(cublasHandle_t handle, cublasFillMode_t uplo,
                          int n, const double          *alpha,
                          const double          *x, int incx, double          *A, int lda)
cublasStatus_t cublasCsyr(cublasHandle_t handle, cublasFillMode_t uplo,
                          int n, const cuComplex       *alpha,
                          const cuComplex       *x, int incx, cuComplex       *A, int lda)
cublasStatus_t cublasZsyr(cublasHandle_t handle, cublasFillMode_t uplo,
                          int n, const cuDoubleComplex *alpha,
                          const cuDoubleComplex *x, int incx, cuDoubleComplex *A, int lda)
```
此函数执行对称矩阵向量乘法。

$y = \alpha xx^T+A$

其中 A 是以列主序存储的 n*n 对称矩阵，x 是向量，而 $\alpha$是标量。

|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|n||input|number of rows and columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|A|device|input|`<type>` array of dimension lda x n with lda>=max(1,n).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[ssyr](http://www.netlib.org/blas/ssyr.f), [dsyr](http://www.netlib.org/blas/dsyr.f)


### 2.6.10. `cublas<t>syr2()`

```c++
cublasStatus_t cublasSsyr2(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                           const float           *alpha, const float           *x, int incx,
                           const float           *y, int incy, float           *A, int lda
cublasStatus_t cublasDsyr2(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                           const double          *alpha, const double          *x, int incx,
                           const double          *y, int incy, double          *A, int lda
cublasStatus_t cublasCsyr2(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                           const cuComplex       *alpha, const cuComplex       *x, int incx,
                           const cuComplex       *y, int incy, cuComplex       *A, int lda
cublasStatus_t cublasZsyr2(cublasHandle_t handle, cublasFillMode_t uplo, int n,
                           const cuDoubleComplex *alpha, const cuDoubleComplex *x, int incx,
                           const cuDoubleComplex *y, int incy, cuDoubleComplex *A, int lda
```

此函数执行对称 rank-2 更新:

$A = \alpha (xy^T + yx^T) + A$

其中 A 是以列主序存储的 n*n 对称矩阵，x和y 是向量，而 $\alpha$是标量。


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|n||input|number of rows and columns of matrix A.|
|alpha|host or device|input|`<type>` scalar used for multiplication.|
|A|device|input|`<type>` array of dimension lda x n with lda>=max(1,n).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|
|y|device|input|`<type>` vector with n elements.|
|incy||input|stride between consecutive elements of y.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[ssyr2](http://www.netlib.org/lapack/explore-html/db/d99/ssyr2_8f_source.html), [dsyr2](http://www.netlib.org/lapack/explore-html/de/d41/dsyr2_8f_source.html)

### 2.6.11. `cublas<t>tbmv()`

```c++
cublasStatus_t cublasStbmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const float           *A, int lda,
                           float           *x, int incx)
cublasStatus_t cublasDtbmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const double          *A, int lda,
                           double          *x, int incx)
cublasStatus_t cublasCtbmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const cuComplex       *A, int lda,
                           cuComplex       *x, int incx)
cublasStatus_t cublasZtbmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const cuDoubleComplex *A, int lda,
                           cuDoubleComplex *x, int incx)
```
此函数执行三角带状矩阵向量乘法

$x = op(A)x$

其中 A 是三角带状矩阵，x 是向量。 此外，对于矩阵 A

$$
op(A)=
\begin{cases}
A\ \ \ \ 如果 transa == CUBLAS\_OP\_N,\\
A^T \ \ 如果 transa == CUBLAS\_OP\_T,\\
A^H \ \ 如果 transa == CUBLAS\_OP\_H
\end{cases}
$$

如果 `uplo == CUBLAS_FILL_MODE_LOWER` 则三角形带状矩阵 A 逐列存储，矩阵的主对角线存储在第 1 行，第 2 行的第一个下对角线（从第一个位置开始），第 3 行的第二个下对角线（开始 在第一个位置）等。因此，一般来说，元素 A(i,j) 存储在内存位置 A(1+i-j,j) 中, 其中i=1,...,n 和 $i \in[j,min(m,j+k)]$ 。 此外，在概念上不对应于带状矩阵（右下角 k*k 三角形）中的元素的数组 A 中的元素不被引用。


如果 `uplo == CUBLAS_FILL_MODE_UPPER` 则三角形带状矩阵 A 逐列存储，矩阵的主对角线存储在第 k+1 行，第 k 行的第一个下对角线（从第一个位置开始），第 k-1 行的第二个下对角线（开始 在第一个位置）等。因此，一般来说，元素 A(1+k+i-j,j) 存储在内存位置 A(1+i-j,j) 中 i=1,...,n 和 $i \in[max(1,j-k),j]$ 。 此外，在概念上不对应于带状矩阵（右下角 k*k 三角形）中的元素的数组 A 中的元素不被引用。

|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|trans||input|operation op(A) that is non- or (conj.) transpose.|
|diag||input|indicates if the elements on the main diagonal of matrix A are unity and should not be accessed.|
|n||input|number of rows and columns of matrix A.|
|k||input|number of sub- and super-diagonals of matrix .|
|A|device|input|`<type>` array of dimension lda x n with lda>=max(1,n).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:
[stbmv](http://www.netlib.org/blas/stbmv.f), [dtbmv](http://www.netlib.org/blas/dtbmv.f), [ctbmv](http://www.netlib.org/blas/ctbmv.f), [ztbmv](http://www.netlib.org/blas/ztbmv.f)


### 2.6.12. `cublas<t>tbsv()`

```c++
cublasStatus_t cublasStbsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const float           *A, int lda,
                           float           *x, int incx)
cublasStatus_t cublasDtbsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const double          *A, int lda,
                           double          *x, int incx)
cublasStatus_t cublasCtbsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const cuComplex       *A, int lda,
                           cuComplex       *x, int incx)
cublasStatus_t cublasZtbsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, int k, const cuDoubleComplex *A, int lda,
                           cuDoubleComplex *x, int incx)
```

此函数执行三角带状矩阵向量乘法

$op(A)x = b $

其中 A 是三角带状矩阵，x 是向量。 此外，对于矩阵 A

$$
op(A)=
\begin{cases}
A\ \ \ \ 如果 transa == CUBLAS\_OP\_N,\\
A^T \ \ 如果 transa == CUBLAS\_OP\_T,\\
A^H \ \ 如果 transa == CUBLAS\_OP\_H
\end{cases}
$$

解决方案 x 在退出时覆盖右侧的 b。

此函数中不包含对奇点或接近奇点的测试。


如果 `uplo == CUBLAS_FILL_MODE_LOWER` 则三角形带状矩阵 A 逐列存储，矩阵的主对角线存储在第 1 行，第 2 行的第一个下对角线（从第一个位置开始），第 3 行的第二个下对角线（开始 在第一个位置）等。因此，一般来说，元素 A(i,j) 存储在内存位置 A(1+i-j,j) 中, 其中i=1,...,n 和 $i \in[j,min(m,j+k)]$ 。 此外，在概念上不对应于带状矩阵（右下角 k*k 三角形）中的元素的数组 A 中的元素不被引用。


如果 `uplo == CUBLAS_FILL_MODE_UPPER` 则三角形带状矩阵 A 逐列存储，矩阵的主对角线存储在第 k+1 行，第 k 行的第一个下对角线（从第一个位置开始），第 k-1 行的第二个下对角线（开始 在第一个位置）等。因此，一般来说，元素 A(1+k+i-j,j) 存储在内存位置 A(1+i-j,j) 中 i=1,...,n 和 $i \in[max(1,j-k),j]$ 。 此外，在概念上不对应于带状矩阵（右下角 k*k 三角形）中的元素的数组 A 中的元素不被引用。



|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|trans||input|operation op(A) that is non- or (conj.) transpose.|
|diag||input|indicates if the elements on the main diagonal of matrix A are unity and should not be accessed.|
|n||input|number of rows and columns of matrix A.|
|k||input|number of sub- and super-diagonals of matrix .|
|A|device|input|`<type>` array of dimension lda x n with lda>=max(1,n).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_INVALID_VALUE|参数 m,n<0 或 incx,incy=0|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[stbsv](http://www.netlib.org/blas/stbsv.f), [dtbsv](http://www.netlib.org/blas/dtbsv.f), [ctbsv](http://www.netlib.org/blas/ctbsv.f), [ztbsv](http://www.netlib.org/blas/ztbsv.f)

### 2.6.13. `cublas<t>tpmv()`

```c++
cublasStatus_t cublasStpmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const float           *AP,
                           float           *x, int incx)
cublasStatus_t cublasDtpmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const double          *AP,
                           double          *x, int incx)
cublasStatus_t cublasCtpmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const cuComplex       *AP,
                           cuComplex       *x, int incx)
cublasStatus_t cublasZtpmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const cuDoubleComplex *AP,
                           cuDoubleComplex *x, int incx)
```


此函数执行三角带状矩阵向量乘法

$x = op(A)x$

其中 A 是三角带状矩阵，x 是向量。 此外，对于矩阵 A

$$
op(A)=
\begin{cases}
A\ \ \ \ 如果 transa == CUBLAS\_OP\_N,\\
A^T \ \ 如果 transa == CUBLAS\_OP\_T,\\
A^H \ \ 如果 transa == CUBLAS\_OP\_H
\end{cases}
$$

解决方案 x 在退出时覆盖右侧的 b。

此函数中不包含对奇点或接近奇点的测试。


如果 `uplo == CUBLAS_FILL_MODE_LOWER `则将三角矩阵下三角部分的元素 A(i, j) 逐列无间隙地打包在一起，从而将元素存储在内存位置 `AP[i+((2*n -j+1)*j)/2]` 对于 j=1 , ...,n 和 i>=j 。 因此，打包格式只需要 $\frac{n(n+1)}{2}$ 个元素进行存储。

如果 `uplo == CUBLAS_FILL_MODE_UPPER `则将三角矩阵下三角部分的元素 A(i, j) 逐列无间隙地打包在一起，从而将元素存储在内存位置 `AP[i+(j*(j+1))/2]` 对于 j=1 , ...,n 和 i<=j 。 因此，打包格式只需要 $\frac{n(n+1)}{2}$ 个元素进行存储。



|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|trans||input|operation op(A) that is non- or (conj.) transpose.|
|diag||input|indicates if the elements on the main diagonal of matrix A are unity and should not be accessed.|
|n||input|number of rows and columns of matrix A.|
|AP|device|input|	`<type>` array with A stored in packed format.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|内部暂存内存分配失败|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[stpmv](http://www.netlib.org/blas/stpmv.f), [dtpmv](http://www.netlib.org/blas/dtpmv.f), [ctpmv](http://www.netlib.org/blas/ctpmv.f), [ztpmv](http://www.netlib.org/blas/ztpmv.f)


### 2.6.14. `cublas<t>tpsv()`

```c++
cublasStatus_t cublasStpsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const float           *AP,
                           float           *x, int incx)
cublasStatus_t cublasDtpsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const double          *AP,
                           double          *x, int incx)
cublasStatus_t cublasCtpsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const cuComplex       *AP,
                           cuComplex       *x, int incx)
cublasStatus_t cublasZtpsv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const cuDoubleComplex *AP,
                           cuDoubleComplex *x, int incx)

```


此函数执行三角带状矩阵向量乘法

$op(A)x = b$

其中 A 是三角带状矩阵，x 是向量。 此外，对于矩阵 A

$$
op(A)=
\begin{cases}
A\ \ \ \ 如果 transa == CUBLAS\_OP\_N,\\
A^T \ \ 如果 transa == CUBLAS\_OP\_T,\\
A^H \ \ 如果 transa == CUBLAS\_OP\_H
\end{cases}
$$

解决方案 x 在退出时覆盖右侧的 b。

此函数中不包含对奇点或接近奇点的测试。


如果 `uplo == CUBLAS_FILL_MODE_LOWER `则将三角矩阵下三角部分的元素 A(i, j) 逐列无间隙地打包在一起，从而将元素存储在内存位置 `AP[i+((2*n -j+1)*j)/2]` 对于 j=1 , ...,n 和 i>=j 。 因此，打包格式只需要 $\frac{n(n+1)}{2}$ 个元素进行存储。

如果 `uplo == CUBLAS_FILL_MODE_UPPER `则将三角矩阵下三角部分的元素 A(i, j) 逐列无间隙地打包在一起，从而将元素存储在内存位置 `AP[i+(j*(j+1))/2]` 对于 j=1 , ...,n 和 i<=j 。 因此，打包格式只需要 $\frac{n(n+1)}{2}$ 个元素进行存储。


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|trans||input|operation op(A) that is non- or (conj.) transpose.|
|diag||input|indicates if the elements on the main diagonal of matrix A are unity and should not be accessed.|
|n||input|number of rows and columns of matrix A.|
|AP|device|input|	`<type>` array with A stored in packed format.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|内部暂存内存分配失败|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[stpsv](http://www.netlib.org/blas/stpsv.f), [dtpsv](http://www.netlib.org/blas/dtpsv.f), [ctpsv](http://www.netlib.org/blas/ctpsv.f), [ztpsv](http://www.netlib.org/blas/ztpsv.f)

### 2.6.15. `cublas<t>trmv()`
```c++
cublasStatus_t cublasStrmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const float           *A, int lda,
                           float           *x, int incx)
cublasStatus_t cublasDtrmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const double          *A, int lda,
                           double          *x, int incx)
cublasStatus_t cublasCtrmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const cuComplex       *A, int lda,
                           cuComplex       *x, int incx)
cublasStatus_t cublasZtrmv(cublasHandle_t handle, cublasFillMode_t uplo,
                           cublasOperation_t trans, cublasDiagType_t diag,
                           int n, const cuDoubleComplex *A, int lda,
                           cuDoubleComplex *x, int incx)

```
此函数执行三角带状矩阵向量乘法

$x = op(A)x$

其中 A 是三角带状矩阵，x 是向量。 此外，对于矩阵 A

$$
op(A)=
\begin{cases}
A\ \ \ \ 如果 transa == CUBLAS\_OP\_N,\\
A^T \ \ 如果 transa == CUBLAS\_OP\_T,\\
A^H \ \ 如果 transa == CUBLAS\_OP\_H
\end{cases}
$$



如果 `uplo == CUBLAS_FILL_MODE_LOWER `则将三角矩阵下三角部分的元素 A(i, j) 逐列无间隙地打包在一起，从而将元素存储在内存位置 `AP[i+((2*n -j+1)*j)/2]` 对于 j=1 , ...,n 和 i>=j 。 因此，打包格式只需要 $\frac{n(n+1)}{2}$ 个元素进行存储。

如果 `uplo == CUBLAS_FILL_MODE_UPPER `则将三角矩阵下三角部分的元素 A(i, j) 逐列无间隙地打包在一起，从而将元素存储在内存位置 `AP[i+(j*(j+1))/2]` 对于 j=1 , ...,n 和 i<=j 。 因此，打包格式只需要 $\frac{n(n+1)}{2}$ 个元素进行存储。


|Param.	|Memory	|In/out|	Meaning|
|----|----|----|----|
|handle||input|handle to the cuBLAS library context.|
|uplo||input|indicates if matrix A lower or upper part is stored, the other symmetric part is not referenced and is inferred from the stored elements.|
|trans||input|operation op(A) that is non- or (conj.) transpose.|
|diag||input|indicates if the elements on the main diagonal of matrix A are unity and should not be accessed.|
|n||input|number of rows and columns of matrix A.|
|A|device|input|		`<type>` array of dimensions lda x n , with lda>=max(1,n).|
|lda||input|leading dimension of two-dimensional array used to store matrix A.|
|x|device|input|	`<type>` vector with n elements.|
|incx||input|stride between consecutive elements of x.|


该函数可能返回的错误值及其含义如下所列。


|ErrorValue|	Meaning|
|----|----|
|CUBLAS_STATUS_SUCCESS|操作成功完成|
|CUBLAS_STATUS_NOT_INITIALIZED|库未初始化|
|CUBLAS_STATUS_ALLOC_FAILED|内部暂存内存分配失败|
|CUBLAS_STATUS_EXECUTION_FAILED|该功能无法在 GPU 上启动|

请参考:

[strmv](http://www.netlib.org/blas/strmv.f), [dtrmv](http://www.netlib.org/blas/dtrmv.f), [ctrmv](http://www.netlib.org/blas/ctrmv.f), [ztrmv](http://www.netlib.org/blas/ztrmv.f)









